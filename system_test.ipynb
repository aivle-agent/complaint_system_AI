{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00fada70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate datasets peft bitsandbytes sentencepiece --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8fd931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec  1 12:11:28 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b185af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8148d2afede940e28f45b492ad6fcd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb8ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'complaint_system_AI'...\n",
      "remote: Enumerating objects: 21, done.\u001b[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 21 (delta 5), reused 8 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (21/21), 12.13 MiB | 7.80 MiB/s, done.\n",
      "Resolving deltas: 100% (5/5), done.\n",
      "/content/complaint_system_AI\n",
      " bandit_prompt_system.py   complain_quality_shap.py   README.md\n",
      " complain_data.zip\t  'Complaint data.zip'\t      system_test.ipynb\n",
      "Archive:  complain_data.zip\n",
      "  inflating: data/중앙행정기관.csv  \n",
      "  inflating: data/국립아시아문화전당.csv  \n",
      "  inflating: data/지방행정기관.csv  \n",
      "  inflating: data/국민신문고.csv  \n",
      "국립아시아문화전당.csv\t지방행정기관.csv  중앙행정기관.csv  국민신문고.csv\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/aivle-agent/complaint_system_AI.git\n",
    "%cd complaint_system_AI\n",
    "\n",
    "!ls\n",
    "\n",
    "!unzip complain_data.zip -d data\n",
    "\n",
    "!ls data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/중앙행정기관.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117deef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1.head(1)['consulting_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138299f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# 0. LLaMA 파이프라인 초기화\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "llama_pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=MODEL_ID,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# 1. 프롬프트 ARM 정의\n",
    "\n",
    "@dataclass\n",
    "class PromptArmConfig:\n",
    "    \"\"\"\n",
    "    각 프롬프트 전략(arm)에 대한 메타 정보.\n",
    "    feature_vector는 이 전략의 성향을 나타내는 임베딩(스타일/목적 가중치 등).\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    feature_vector: np.ndarray  # shape = (d,)\n",
    "\n",
    "# 2. Logistic Bandit (arm별 w, H + UCB)\n",
    "\n",
    "class LogisticPromptBandit:\n",
    "    \"\"\"\n",
    "    프롬프트 전략 선택용 logistic bandit.\n",
    "    - 각 arm별로 logistic 모델 w_a, H_a 유지\n",
    "    - UCB 스타일로 exploration (mean + beta * uncertainty)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        lambda_reg: float = 1.0,\n",
    "        eta: float = 0.1,\n",
    "        beta: float = 1.0,\n",
    "    ):\n",
    "        self.arms = arms\n",
    "        self.n_arms = len(arms)\n",
    "        self.d = arms[0].feature_vector.shape[0]\n",
    "\n",
    "        # arm별 parameter, Hessian 근사\n",
    "        self.w = np.zeros((self.n_arms, self.d))  # w_a\n",
    "        self.H = [lambda_reg * np.eye(self.d) for _ in range(self.n_arms)]\n",
    "\n",
    "        self.eta = eta   # step size\n",
    "        self.beta = beta # exploration 강도\n",
    "\n",
    "    def _sigmoid(self, z: float) -> float:\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def select_arm(self) -> int:\n",
    "        \"\"\"\n",
    "        현재까지의 w, H를 기반으로 어느 프롬프트 전략 arm을 쓸지 선택.\n",
    "        score_a = (w_a^T x_a) + beta * sqrt( x_a^T H_a^{-1} x_a )\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = arm.feature_vector  # (d,)\n",
    "            mean = float(self.w[a_idx].dot(x))\n",
    "\n",
    "            invH = np.linalg.inv(self.H[a_idx])\n",
    "            var = float(x.T @ invH @ x)\n",
    "            ucb = self.beta * np.sqrt(max(var, 1e-12))\n",
    "\n",
    "            scores.append(mean + ucb)\n",
    "\n",
    "        chosen = int(np.argmax(scores))\n",
    "        return chosen\n",
    "\n",
    "    def update(self, arm_idx: int, reward: float):\n",
    "        \"\"\"\n",
    "        bandit reward(0~1 범위)를 받아 online logistic regression update.\n",
    "        reward는 verifier에서 나온 스칼라 점수.\n",
    "        \"\"\"\n",
    "        arm = self.arms[arm_idx]\n",
    "        x = arm.feature_vector\n",
    "        z = float(self.w[arm_idx].dot(x))\n",
    "        p = self._sigmoid(z)  # 현재 model이 보는 \"성공 확률\"\n",
    "\n",
    "        # logistic loss gradient: -(y - p) * x\n",
    "        grad = -(reward - p) * x\n",
    "\n",
    "        # Hessian 근사 업데이트: H_a += x x^T\n",
    "        self.H[arm_idx] += np.outer(x, x)\n",
    "\n",
    "        # Online Newton-style step: w <- w - eta * H^{-1} grad\n",
    "        invH = np.linalg.inv(self.H[arm_idx])\n",
    "        step = self.eta * (invH @ grad)\n",
    "        self.w[arm_idx] -= step\n",
    "\n",
    "    def explain_current_strategy(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        각 arm에 대해 현재 bandit가 보는 \"예상 성공도\"를 텍스트로 정리.\n",
    "        \"\"\"\n",
    "        lines = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = arm.feature_vector\n",
    "            z = float(self.w[a_idx].dot(x))\n",
    "            p = self._sigmoid(z)\n",
    "            lines.append(\n",
    "                f\"[{arm.name}] \"\n",
    "                f\"예상 성공도 ≈ {p:.3f} | \"\n",
    "                f\"feature={np.round(x, 2)} | \"\n",
    "                f\"설명: {arm.description}\"\n",
    "            )\n",
    "        return lines\n",
    "\n",
    "# 3. LLM Generator (Meta-Llama-3 기반)\n",
    "\n",
    "\n",
    "class LlamaChatGenerator:\n",
    "    def __init__(self, base_model, lora_path=None):\n",
    "        from peft import PeftModel\n",
    "\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(base_model)\n",
    "        model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "            base_model, torch_dtype=torch.bfloat16, device_map=\"auto\"\n",
    "        )\n",
    "\n",
    "        if lora_path:\n",
    "            model = PeftModel.from_pretrained(model, lora_path)\n",
    "\n",
    "        self.pipe = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "    def generate(self, system_prompt, user_prompt):\n",
    "        msgs = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "        out = self.pipe(\n",
    "            msgs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            top_p=0.9,\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        # assistant role만 추출\n",
    "        if isinstance(out, list):\n",
    "            for m in out:\n",
    "                if m.get(\"role\") == \"assistant\":\n",
    "                    return m[\"content\"]\n",
    "        return str(out)\n",
    "\n",
    "\n",
    "\n",
    "def build_prompt_from_arm(\n",
    "    base_instruction: str,\n",
    "    complaint_text: str,\n",
    "    arm: PromptArmConfig,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    arm의 전략 설명을 user 프롬프트에 녹여서 스타일/방향을 제어.\n",
    "    - base_instruction: system 쪽에 들어가는 역할/전략 기본 설명\n",
    "    - 여기서 반환하는 건 user_prompt에 들어갈 텍스트\n",
    "    \"\"\"\n",
    "    return (\n",
    "        f\"아래 민원에 대해 답변을 작성하되, 다음 전략 프로필을 따르세요.\\n\\n\"\n",
    "        f\"[전략 이름]\\n{arm.name}\\n\\n\"\n",
    "        f\"[전략 설명]\\n{arm.description}\\n\\n\"\n",
    "        f\"[민원 내용]\\n{complaint_text}\\n\\n\"\n",
    "        f\"[추가 지침]\\n\"\n",
    "        f\"- 관련 법령/정책과의 일치성을 확인하고, 처리 가능/불가능을 명확히 구분하세요.\\n\"\n",
    "        f\"- 민원인이 이해하기 쉬운 구조로 답변하고, 필요한 경우 대안/절차를 제시하세요.\\n\"\n",
    "        f\"- 과도한 약속이나 확정적인 표현은 피하고, '담당 부서의 최종 판단'이 필요함을 밝혀주세요.\\n\"\n",
    "    )\n",
    "\n",
    "# 4. Verifier: LLM 기반 점수 → reward\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VerificationScores:\n",
    "    \"\"\"각 품질 지표 스코어 (0~1).\"\"\"\n",
    "    resolution_likelihood: float    # 실제로 해결/처리가 될 가능성\n",
    "    policy_legal_alignment: float   # 정책/법령·과거 답변과의 일치도\n",
    "    explanation_clarity: float      # 구조/논리/명료성\n",
    "    empathy_tone: float             # 민원인 친화적 톤, 갈등 완화\n",
    "    risk_safety: float              # 기관 입장에서의 안전성 (높을수록 안전)\n",
    "\n",
    "\n",
    "class SmallVerifier:\n",
    "    def __init__(self, base_model, lora_path=None):\n",
    "        from peft import PeftModel\n",
    "\n",
    "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(base_model)\n",
    "        model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "            base_model,\n",
    "            num_labels=1,   # 0~1 점수\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "\n",
    "        if lora_path:\n",
    "            model = PeftModel.from_pretrained(model, lora_path)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def evaluate(self, complaint, answer):\n",
    "        text = f\"[COMPLAINT]\\n{complaint}\\n\\n[ANSWER]\\n{answer}\"\n",
    "        inputs = self.tokenizer(text, truncation=True, max_length=2048, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            score = torch.sigmoid(self.model(**inputs).logits)[0].item()\n",
    "        return score\n",
    "\n",
    "\n",
    "def aggregate_reward(\n",
    "    scores: VerificationScores,\n",
    "    weights: Optional[Dict[str, float]] = None,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    reward 구조:\n",
    "      r = w1 * 해결 가능성\n",
    "        + w2 * 정책/법률 일치\n",
    "        + w3 * 명료성\n",
    "        + w4 * 공감\n",
    "        + w5 * 안전성\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            \"resolution_likelihood\": 0.35,\n",
    "            \"policy_legal_alignment\": 0.25,\n",
    "            \"explanation_clarity\": 0.20,\n",
    "            \"empathy_tone\": 0.10,\n",
    "            \"risk_safety\": 0.10,\n",
    "        }\n",
    "\n",
    "    s = (\n",
    "        scores.resolution_likelihood * weights[\"resolution_likelihood\"]\n",
    "        + scores.policy_legal_alignment * weights[\"policy_legal_alignment\"]\n",
    "        + scores.explanation_clarity * weights[\"explanation_clarity\"]\n",
    "        + scores.empathy_tone * weights[\"empathy_tone\"]\n",
    "        + scores.risk_safety * weights[\"risk_safety\"]\n",
    "    )\n",
    "\n",
    "    return float(max(0.0, min(1.0, s)))\n",
    "\n",
    "# 5. 전체 엔진: bandit → generator → verifier → bandit update\n",
    "\n",
    "class PromptBanditEngine:\n",
    "    \"\"\"\n",
    "    - bandit이 프롬프트 전략 선택\n",
    "    - LLM이 답변 생성\n",
    "    - verifier가 품질 측정 → reward 산출\n",
    "    - bandit 업데이트\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        base_instruction: str,\n",
    "        llm: LlamaChatGenerator,\n",
    "        verifier: LlamaVerifier,\n",
    "    ):\n",
    "        self.bandit = LogisticPromptBandit(arms=arms)\n",
    "        self.base_instruction = base_instruction\n",
    "        self.llm = llm\n",
    "        self.verifier = verifier\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        complaint_text: str,\n",
    "        reward_weights: Optional[Dict[str, float]] = None,\n",
    "        extra_context: str = \"\",\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        민원 1건에 대해:\n",
    "          1) bandit으로 전략 arm 선택\n",
    "          2) 해당 전략으로 user_prompt 구성 + LLM 답변\n",
    "          3) verifier로 평가 + reward\n",
    "          4) bandit update\n",
    "          5) 결과/로그 반환\n",
    "        \"\"\"\n",
    "        # 1. arm 선택\n",
    "        arm_idx = self.bandit.select_arm()\n",
    "        arm = self.bandit.arms[arm_idx]\n",
    "\n",
    "        # 2. prompt 구성 + LLM 답변\n",
    "        user_prompt = build_prompt_from_arm(\n",
    "            base_instruction=self.base_instruction,\n",
    "            complaint_text=complaint_text,\n",
    "            arm=arm,\n",
    "        )\n",
    "        answer = self.llm.generate(\n",
    "            system_prompt=self.base_instruction,\n",
    "            user_prompt=user_prompt,\n",
    "        )\n",
    "\n",
    "        # 3. verifier 평가\n",
    "        scores = self.verifier.evaluate(\n",
    "            complaint_text=complaint_text,\n",
    "            answer_text=answer,\n",
    "            extra_context=extra_context,\n",
    "        )\n",
    "        reward = aggregate_reward(scores, weights=reward_weights)\n",
    "\n",
    "        # 4. bandit 업데이트\n",
    "        self.bandit.update(arm_idx=arm_idx, reward=reward)\n",
    "\n",
    "        # 5. 현재 전략 방향성 요약\n",
    "        strategy_view = self.bandit.explain_current_strategy()\n",
    "\n",
    "        return {\n",
    "            \"chosen_arm_idx\": arm_idx,\n",
    "            \"chosen_arm_name\": arm.name,\n",
    "            \"chosen_arm_description\": arm.description,\n",
    "            \"user_prompt\": user_prompt,\n",
    "            \"answer\": answer,\n",
    "            \"verification_scores\": scores,\n",
    "            \"reward\": reward,\n",
    "            \"strategy_view\": strategy_view,\n",
    "        }\n",
    "\n",
    "\n",
    "# 6. to be decided\n",
    "\n",
    "def build_default_arms() -> List[PromptArmConfig]:\n",
    "    \"\"\"\n",
    "      [법률/정책 중시 정도, 해결책 제안 정도, 공감/톤, 단호함(제한 강조), 근거 제시 강조]\n",
    "    \"\"\"\n",
    "    return [\n",
    "        PromptArmConfig(\n",
    "            name=\"법률-정책 최우선\",\n",
    "            description=\"법령, 조례, 내부지침과의 일치성을 최우선으로 하고 책임 범위를 분명히 하는 보수적 답변.\",\n",
    "            feature_vector=np.array([0.9, 0.6, 0.4, 0.8, 0.7]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"민원인 공감형\",\n",
    "            description=\"민원인의 감정과 상황을 충분히 공감하고, 이해하기 쉬운 언어로 절차와 한계를 설명하는 답변.\",\n",
    "            feature_vector=np.array([0.6, 0.7, 0.9, 0.3, 0.5]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"해결책 제안형\",\n",
    "            description=\"현실적으로 가능한 대안과 행동 옵션을 최대한 많이 제시하는 해결 중심 답변.\",\n",
    "            feature_vector=np.array([0.7, 0.9, 0.7, 0.4, 0.8]),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "def main():\n",
    "    arms = build_default_arms()\n",
    "\n",
    "    generator = LlamaChatGenerator(\n",
    "        base_model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        lora_path=\"./gen_lora\"\n",
    "    )\n",
    "\n",
    "    verifier = SmallVerifier(\n",
    "        base_model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        lora_path=\"./verifier_lora\"\n",
    "    )\n",
    "\n",
    "    engine = PromptBanditEngine(\n",
    "        arms=arms,\n",
    "        base_instruction=BASE_SYS_PROMPT,\n",
    "        llm=generator,\n",
    "        verifier=verifier,\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for idx, row in tqdm(wide.iterrows(), total=len(wide)):\n",
    "        complaint = row[\"complaint_text\"]\n",
    "        context = row.get(\"topic\", \"\")\n",
    "\n",
    "        out = engine.step(complaint, extra_context=context)\n",
    "\n",
    "        results.append({\n",
    "            \"complaint\": complaint,\n",
    "            \"answer\": out[\"answer\"],\n",
    "            \"reward\": out[\"reward\"],\n",
    "            \"arm\": out[\"chosen_arm_name\"]\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(\"full_batch_results.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a68d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers peft accelerate bitsandbytes sentencepiece sentence-transformers scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "\n",
    "#############################################\n",
    "# 1) 민원 텍스트에서 Q / A 분리\n",
    "#############################################\n",
    "\n",
    "def parse_qa(text: str):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    # Q: ~~~ A: ~~~ 구조에서 Q, A 각각 분리\n",
    "    q_match = re.search(r\"Q\\s*:\\s*(.*?)(?:A\\s*:|$)\", text, flags=re.DOTALL)\n",
    "    a_match = re.search(r\"A\\s*:\\s*(.*)\", text, flags=re.DOTALL)\n",
    "\n",
    "    q = q_match.group(1).strip() if q_match else \"\"\n",
    "    a = a_match.group(1).strip() if a_match else \"\"\n",
    "    return q, a\n",
    "\n",
    "def clean_text(x: Any) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "    x = re.sub(r\"\\d{2,3}-\\d{3,4}-\\d{4}\", \"[TEL]\", x)\n",
    "    x = re.sub(r\"\\d{6}-\\d{7}\", \"[RRN]\", x)\n",
    "    x = re.sub(r\"[가-힣]{2,3}씨\", \"[NAME]\", x)\n",
    "    return x.strip()\n",
    "\n",
    "def convert_df_to_qa(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        content = row.get(\"consulting_content\", \"\")\n",
    "        q_raw, a_raw = parse_qa(content)\n",
    "\n",
    "        q = clean_text(q_raw)\n",
    "        a = clean_text(a_raw)\n",
    "\n",
    "        if len(q) < 5 or len(a) < 5:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": a,\n",
    "            \"source\": row.get(\"source\", \"\"),\n",
    "            \"date\": row.get(\"consulting_date\", \"\"),\n",
    "            \"category\": row.get(\"consulting_category\", \"\"),\n",
    "            \"classification\": row.get(\"classification\", \"\")\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# 4) Dataset Builder (generator/verifier 학습용)\n",
    "\n",
    "\n",
    "def build_dataset(df: pd.DataFrame):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        q = clean_text(row.get(\"question\", \"\"))\n",
    "        a = clean_text(row.get(\"answer\", \"\"))\n",
    "\n",
    "        if len(q) < 5 or len(a) < 5:\n",
    "            continue\n",
    "\n",
    "        data.append({\"question\": q, \"answer\": a})\n",
    "    return data\n",
    "\n",
    "# 5) Train/Test Split\n",
    "\n",
    "\n",
    "def split_dataset(all_data, test_ratio=0.1):\n",
    "    total = len(all_data)\n",
    "    test_size = max(1, int(total * test_ratio))\n",
    "    return all_data[:-test_size], all_data[-test_size:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. 프롬프트 전략 ARM 정의\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PromptArmConfig:\n",
    "    name: str\n",
    "    description: str\n",
    "    feature_vector: np.ndarray   \n",
    "\n",
    "\n",
    "def build_prompt_arms() -> List[PromptArmConfig]:\n",
    "    return [\n",
    "        PromptArmConfig(\n",
    "            name=\"법률-정책 최우선\",\n",
    "            description=\"법령·조례·내부지침과의 일치성을 최우선으로 하고, 책임 범위를 명확히 하는 보수적 답변.\",\n",
    "            feature_vector=np.array([0.9, 0.4, 0.5]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"민원인 공감형\",\n",
    "            description=\"민원인의 감정과 상황을 충분히 공감하고, 이해하기 쉬운 언어로 절차와 한계를 설명하는 답변.\",\n",
    "            feature_vector=np.array([0.6, 0.9, 0.6]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"해결책 제안형\",\n",
    "            description=\"현실적으로 가능한 대안과 행동 옵션을 적극적으로 제시하는 해결 중심 답변.\",\n",
    "            feature_vector=np.array([0.7, 0.6, 0.9]),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "# 3. Contextual Logistic Bandit\n",
    "#    (arm feature + complaint context feature)\n",
    "# \n",
    "\n",
    "class ContextualLogisticPromptBandit:\n",
    "    \"\"\"\n",
    "    Contextual Bandit:\n",
    "      - 각 arm마다 고정 feature_vector\n",
    "      - 각 민원마다 context_vec (질문 길이, 구체성, 클러스터 등)\n",
    "      - 입력 phi = concat(arm_feature, ctx_vec)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        ctx_dim: int,\n",
    "        lambda_reg: float = 1.0,\n",
    "        eta: float = 0.1,\n",
    "        beta: float = 1.0,\n",
    "    ):\n",
    "        self.arms = arms\n",
    "        self.n_arms = len(arms)\n",
    "        self.d_arm = arms[0].feature_vector.shape[0]\n",
    "        self.d_ctx = ctx_dim\n",
    "        self.d = self.d_arm + self.d_ctx\n",
    "\n",
    "        # arm별 parameter, Hessian 근사\n",
    "        self.w = np.zeros((self.n_arms, self.d))\n",
    "        self.H = [lambda_reg * np.eye(self.d) for _ in range(self.n_arms)]\n",
    "\n",
    "        self.eta = eta\n",
    "        self.beta = beta\n",
    "\n",
    "    def _sigmoid(self, z: float) -> float:\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def _phi(self, arm_idx: int, ctx_vec: np.ndarray) -> np.ndarray:\n",
    "        arm_feat = self.arms[arm_idx].feature_vector\n",
    "        return np.concatenate([arm_feat, ctx_vec])  # (d,)\n",
    "\n",
    "    def select_arm(self, ctx_vec: np.ndarray) -> int:\n",
    "        scores = []\n",
    "        for a_idx in range(self.n_arms):\n",
    "            x = self._phi(a_idx, ctx_vec)\n",
    "            mean = float(self.w[a_idx].dot(x))\n",
    "\n",
    "            invH = np.linalg.inv(self.H[a_idx])\n",
    "            var = float(x.T @ invH @ x)\n",
    "            ucb = self.beta * np.sqrt(max(var, 1e-12))\n",
    "\n",
    "            scores.append(mean + ucb)\n",
    "        return int(np.argmax(scores))\n",
    "\n",
    "    def update(self, arm_idx: int, ctx_vec: np.ndarray, reward: float):\n",
    "        x = self._phi(arm_idx, ctx_vec)\n",
    "        z = float(self.w[arm_idx].dot(x))\n",
    "        p = self._sigmoid(z)\n",
    "\n",
    "        grad = -(reward - p) * x\n",
    "        self.H[arm_idx] += np.outer(x, x)\n",
    "\n",
    "        invH = np.linalg.inv(self.H[arm_idx])\n",
    "        step = self.eta * (invH @ grad)\n",
    "        self.w[arm_idx] -= step\n",
    "\n",
    "    def explain_current_strategy(self, ctx_vec: np.ndarray) -> List[str]:\n",
    "        lines = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = self._phi(a_idx, ctx_vec)\n",
    "            z = float(self.w[a_idx].dot(x))\n",
    "            p = self._sigmoid(z)\n",
    "            lines.append(\n",
    "                f\"[{arm.name}] 예상 성공도 ≈ {p:.3f} | arm_feat={np.round(arm.feature_vector, 2)}\"\n",
    "            )\n",
    "        return lines\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Question Refiner (간단 버전; 나중에 LLM으로 교체 가능)\n",
    "# ============================================================\n",
    "\n",
    "class SimpleQuestionRefiner:\n",
    "    \"\"\"\n",
    "    지금은 간단히 공백 정리 + 기본 클리닝만 수행.\n",
    "    나중에 LLM 기반으로 '질문 구조 교정' 로직으로 교체 가능.\n",
    "    \"\"\"\n",
    "    def refine(self, raw_text: str) -> str:\n",
    "        t = clean_text(raw_text)\n",
    "        # TODO: 여기에 LLM 기반 재구성 로직을 넣어도 됨.\n",
    "        return t\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. DBSCAN 기반 민원 유형화 (임베딩 + 클러스터)\n",
    "# ============================================================\n",
    "\n",
    "class ComplaintClusterer:\n",
    "    \"\"\"\n",
    "    - SentenceTransformer로 임베딩\n",
    "    - DBSCAN으로 군집\n",
    "    - 새로운 민원 → 임베딩 → 가장 유사한 기존 포인트의 클러스터 라벨 사용\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"jhgan/ko-sroberta-multitask\", eps=0.4, min_samples=5):\n",
    "        self.encoder = SentenceTransformer(model_name)\n",
    "        self.dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric=\"cosine\")\n",
    "        self.embeddings = None\n",
    "        self.labels = None\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.embeddings = self.encoder.encode(\n",
    "            texts,\n",
    "            batch_size=32,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        self.dbscan.fit(self.embeddings)\n",
    "        self.labels = self.dbscan.labels_\n",
    "        print(\"클러스터 개수(노이즈 포함):\", len(set(self.labels)))\n",
    "\n",
    "    def predict_cluster(self, text: str) -> int:\n",
    "        if self.embeddings is None or self.labels is None:\n",
    "            return -1\n",
    "        emb = self.encoder.encode([text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "        sims = cosine_similarity(emb, self.embeddings)[0]\n",
    "        idx = int(np.argmax(sims))\n",
    "        return int(self.labels[idx])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. Context Vector 생성 (질문 특성 + 클러스터)\n",
    "# ============================================================\n",
    "\n",
    "def build_context_vector(refined_q: str, cluster_id: int) -> np.ndarray:\n",
    "    # 길이 (0~1 스케일)\n",
    "    length = min(len(refined_q) / 500.0, 1.0)\n",
    "    # 문장 수 (0~1 스케일)\n",
    "    num_sent = refined_q.count(\"다.\") + refined_q.count(\".\")\n",
    "    num_sent = min(num_sent / 10.0, 1.0)\n",
    "    # 법률 관련 키워드 여부\n",
    "    has_law = 1.0 if any(k in refined_q for k in [\"법\", \"조항\", \"제\", \"시행령\"]) else 0.0\n",
    "    # 클러스터 id normalize (대충 0~1로)\n",
    "    cluster_norm = 0.0 if cluster_id == -1 else (cluster_id % 20) / 20.0\n",
    "\n",
    "    return np.array([length, num_sent, has_law, cluster_norm], dtype=float)\n",
    "\n",
    "\n",
    "# 7. Generator (LLaMA) + Verifier (Phi-3)\n",
    "\n",
    "\n",
    "class LlamaChatGenerator:\n",
    "    def __init__(self, model_id=\"meta-llama/Meta-Llama-3-8B-Instruct\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        self.pipe = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "    def generate(self, system_prompt: str, user_prompt: str, max_new_tokens: int = 256):\n",
    "        msgs = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "        out = self.pipe(\n",
    "            msgs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.2,\n",
    "            top_p=0.9,\n",
    "        )[0][\"generated_text\"]\n",
    "        return str(out)\n",
    "\n",
    "\n",
    "class PhiMiniVerifier:\n",
    "    \"\"\"\n",
    "    Q/A를 입력으로 받아 0~1 신뢰도 점수 출력.\n",
    "    (지금은 단일 score지만, 나중에 다중 지표 확장 가능)\n",
    "    \"\"\"\n",
    "    def __init__(self, model_id=\"microsoft/Phi-3-mini-4k-instruct\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_id,\n",
    "            num_labels=1,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "    def score(self, question: str, answer: str) -> float:\n",
    "        text = f\"[QUESTION]\\n{question}\\n\\n[ANSWER]\\n{answer}\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=2048,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "            prob = torch.sigmoid(logits)[0].item()\n",
    "        return float(prob)\n",
    "\n",
    "# 8. 프롬프트 조립\n",
    "\n",
    "\n",
    "BASE_SYS_PROMPT = (\n",
    "    \"당신은 한국 공공기관의 민원 보조 AI입니다. \"\n",
    "    \"사실과 법령, 정책과의 일치성, 절차 안내를 중시하며, \"\n",
    "    \"과도한 약속이나 확정적인 표현은 피해야 합니다.\"\n",
    ")\n",
    "\n",
    "def build_prompt_from_arm(\n",
    "    complaint_text: str,\n",
    "    arm: PromptArmConfig,\n",
    ") -> str:\n",
    "    return (\n",
    "        f\"아래 민원에 대해 답변을 작성하되, 제시된 전략 프로필을 따르세요.\\n\\n\"\n",
    "        f\"[전략 이름]\\n{arm.name}\\n\\n\"\n",
    "        f\"[전략 설명]\\n{arm.description}\\n\\n\"\n",
    "        f\"[민원 내용]\\n{complaint_text}\\n\\n\"\n",
    "        f\"[추가 지침]\\n\"\n",
    "        f\"- 관련 법령/정책과의 일치성을 확인하고, 처리 가능/불가능을 명확히 구분하세요.\\n\"\n",
    "        f\"- 민원인이 이해하기 쉬운 구조(요약 → 근거 → 절차 → 주의사항)로 답변하세요.\\n\"\n",
    "        f\"- 과도한 약속이나 확정적인 표현은 피하고, \"\n",
    "        f\"'실제 처리 여부는 담당 부서의 최종 판단에 따릅니다.'라는 문장을 반드시 포함하세요.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. 전체 엔진: Refiner → Cluster → Bandit → Generator → Verifier\n",
    "# ============================================================\n",
    "\n",
    "class ComplaintEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        generator: LlamaChatGenerator,\n",
    "        verifier: PhiMiniVerifier,\n",
    "        clusterer: ComplaintClusterer,\n",
    "        refiner: SimpleQuestionRefiner,\n",
    "        ctx_dim: int,\n",
    "    ):\n",
    "        self.arms = arms\n",
    "        self.generator = generator\n",
    "        self.verifier = verifier\n",
    "        self.clusterer = clusterer\n",
    "        self.refiner = refiner\n",
    "        self.bandit = ContextualLogisticPromptBandit(arms=arms, ctx_dim=ctx_dim)\n",
    "\n",
    "    def step(self, raw_complaint: str) -> Dict[str, Any]:\n",
    "        # 1) 질문 교정\n",
    "        refined_q = self.refiner.refine(raw_complaint)\n",
    "\n",
    "        # 2) DBSCAN 기반 유형 클러스터\n",
    "        cluster_id = self.clusterer.predict_cluster(refined_q)\n",
    "\n",
    "        # 3) Context feature 벡터\n",
    "        ctx_vec = build_context_vector(refined_q, cluster_id)\n",
    "\n",
    "        # 4) Bandit으로 arm 선택\n",
    "        arm_idx = self.bandit.select_arm(ctx_vec)\n",
    "        arm = self.arms[arm_idx]\n",
    "\n",
    "        # 5) Generator 호출 프롬프트 생성\n",
    "        user_prompt = build_prompt_from_arm(refined_q, arm)\n",
    "        answer = self.generator.generate(BASE_SYS_PROMPT, user_prompt)\n",
    "\n",
    "        # 6) Verifier 점수 → reward\n",
    "        reward = self.verifier.score(refined_q, answer)\n",
    "\n",
    "        # 7) Bandit 업데이트\n",
    "        self.bandit.update(arm_idx, ctx_vec, reward)\n",
    "\n",
    "        # 8) 전략 요약 (현재 context 기준 추정)\n",
    "        strat_view = self.bandit.explain_current_strategy(ctx_vec)\n",
    "\n",
    "        return {\n",
    "            \"raw_complaint\": raw_complaint,\n",
    "            \"refined_complaint\": refined_q,\n",
    "            \"cluster_id\": cluster_id,\n",
    "            \"context_vec\": ctx_vec,\n",
    "            \"chosen_arm_idx\": arm_idx,\n",
    "            \"chosen_arm_name\": arm.name,\n",
    "            \"answer\": answer,\n",
    "            \"reward\": reward,\n",
    "            \"strategy_view\": strat_view,\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10. 배치 평가 (Train/Test 중 Test 파트에 대해)\n",
    "# ============================================================\n",
    "\n",
    "def evaluate_batch(engine: ComplaintEngine, test_data, out_csv=\"batch_results.csv\"):\n",
    "    logs = []\n",
    "    for item in tqdm(test_data):\n",
    "        q = item[\"question\"]\n",
    "        out = engine.step(q)\n",
    "        logs.append({\n",
    "            \"question\": q,\n",
    "            \"refined_question\": out[\"refined_complaint\"],\n",
    "            \"cluster_id\": out[\"cluster_id\"],\n",
    "            \"arm\": out[\"chosen_arm_name\"],\n",
    "            \"score\": out[\"reward\"],\n",
    "            \"answer\": out[\"answer\"],\n",
    "        })\n",
    "    df = pd.DataFrame(logs)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11. 실시간 서비스용 래퍼\n",
    "# ============================================================\n",
    "\n",
    "def ask(engine: ComplaintEngine, complaint: str):\n",
    "    out = engine.step(complaint)\n",
    "    print(\"========================================\")\n",
    "    print(\"[선택된 전략] \", out[\"chosen_arm_name\"])\n",
    "    print(\"[클러스터 ID]\", out[\"cluster_id\"])\n",
    "    print(\"[컨텍스트 벡터]\", np.round(out[\"context_vec\"], 3))\n",
    "    print(\"\\n[교정된 민원]\\n\", out[\"refined_complaint\"])\n",
    "    print(\"\\n[예상 답변 앞부분]\\n\", out[\"answer\"][:800])\n",
    "    print(\"\\n[Verifier 기반 신뢰도 score] \", round(out[\"reward\"], 3))\n",
    "    print(\"\\n[현재 Bandit 전략 뷰]\")\n",
    "    for line in out[\"strategy_view\"]:\n",
    "        print(\"  \", line)\n",
    "    print(\"========================================\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# 12. MAIN: 전체 흐름 연결\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 0) 원본 CSV 로드\n",
    "    raw = pd.read_csv('data/중앙행정기관.csv')\n",
    "\n",
    "    # 1) Q/A 분리된 DF 생성\n",
    "    qa_df = convert_df_to_qa(raw)\n",
    "    print(\"QA rows:\", len(qa_df))\n",
    "    print(qa_df.head(2))\n",
    "\n",
    "    # 2) build_dataset + train/test split\n",
    "    all_data = build_dataset(qa_df)\n",
    "    print(\"Total usable Q/A pairs:\", len(all_data))\n",
    "\n",
    "    train_data, test_data = split_dataset(all_data, test_ratio=0.1)\n",
    "    print(\"Train size:\", len(train_data), \"Test size:\", len(test_data))\n",
    "\n",
    "    # 3) 클러스터링에 쓸 질문 텍스트\n",
    "    train_questions = [d[\"question\"] for d in train_data]\n",
    "\n",
    "    print(\"Train questions for clustering:\", len(train_questions))\n",
    "    if len(train_questions) == 0:\n",
    "        raise RuntimeError(\"No questions available for clustering. Check parsing/filters.\")\n",
    "\n",
    "    # 4) 클러스터러 학습\n",
    "    clusterer = ComplaintClusterer()\n",
    "    clusterer.fit(train_questions)\n",
    "\n",
    "    # 3) 컴포넌트 초기화\n",
    "    arms = build_prompt_arms()\n",
    "    generator = LlamaChatGenerator(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "    verifier = PhiMiniVerifier(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "    refiner = SimpleQuestionRefiner()\n",
    "\n",
    "    engine = ComplaintEngine(\n",
    "        arms=arms,\n",
    "        generator=generator,\n",
    "        verifier=verifier,\n",
    "        clusterer=clusterer,\n",
    "        refiner=refiner,\n",
    "        ctx_dim=4,   # build_context_vector에서 4차원 벡터 생성\n",
    "    )\n",
    "\n",
    "    # 4) Test 일부에 대한 배치 평가\n",
    "    print(\"\\n Test set 일부(예: 20개)에 대한 평가 실행 중...\")\n",
    "    df_res = evaluate_batch(engine, test_data[:20], out_csv=\"batch_results_sample.csv\")\n",
    "    print(\"샘플 결과 saved to batch_results_sample.csv\")\n",
    "    display(df_res.head())\n",
    "\n",
    "    # 5) 실시간 예시\n",
    "    print(\"\\n 실시간 예시 민원 입력 테스트\")\n",
    "    _ = ask(engine, \"우리 아파트 단지 앞 도로에 불법주차 차량이 많아서 사고 위험이 큽니다. 어떤 조치를 받을 수 있나요?\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34249ec",
   "metadata": {},
   "source": [
    "real test zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5bd974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Collecting transformers>=4.40.0\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40.0) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40.0) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m144.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.2\n",
      "    Uninstalling transformers-4.57.2:\n",
      "      Successfully uninstalled transformers-4.57.2\n",
      "Successfully installed transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"transformers>=4.40.0\" \"accelerate\" \"peft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e43f5431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 Q/A 개수: 4447\n",
      "Train: 3559, Val: 444, Test: 444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generator] LoRA trainable params: 2252800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2670' max='2670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2670/2670 3:13:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.200600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.962200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.898800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.880400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.866800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.866500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.858200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.859900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.843500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.852700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.861400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.852600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56/56 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generator] Eval metrics: {'eval_loss': 0.8639466762542725, 'eval_runtime': 219.7461, 'eval_samples_per_second': 2.021, 'eval_steps_per_second': 0.255, 'epoch': 3.0}\n",
      "[Generator] Eval Perplexity ≈ 2.373\n",
      "[Generator LoRA] Saved to ./gen_lora\n"
     ]
    }
   ],
   "source": [
    "# ===================== Generator LoRA 학습 =====================\n",
    "import math\n",
    "import re\n",
    "from typing import Any, List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# ---- 0) 공통 유틸 (질문/답변 추출용) ----\n",
    "\n",
    "def clean_text(x: Any) -> str:\n",
    "    \"\"\"전화번호, 주민번호, 이름 패턴 등을 마스킹하고 strip.\"\"\"\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "    x = re.sub(r\"\\d{2,3}-\\d{3,4}-\\d{4}\", \"[TEL]\", x)\n",
    "    x = re.sub(r\"\\d{6}-\\d{7}\", \"[RRN]\", x)\n",
    "    x = re.sub(r\"[가-힣]{2,3}씨\", \"[NAME]\", x)\n",
    "    return x.strip()\n",
    "\n",
    "\n",
    "def parse_question_answer(full_text: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    중앙행정기관 데이터의 consulting_content/complaint_text에서\n",
    "    Q/A 부분을 분리한다.\n",
    "\n",
    "    대략적인 패턴:\n",
    "      \"제목 : ...\\n\\nQ : ...\\n...\\n\\nA : ...\"\n",
    "\n",
    "    Q/A 구분이 애매한 경우엔 heuristic.\n",
    "    \"\"\"\n",
    "    if not isinstance(full_text, str):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    text = full_text.strip()\n",
    "\n",
    "    # 1) \"A :\" 기준으로 먼저 자르기\n",
    "    a_idx = text.find(\"\\nA :\")\n",
    "    if a_idx == -1:\n",
    "        a_idx = text.find(\"\\n\\nA :\")\n",
    "    if a_idx == -1:\n",
    "        a_idx = text.find(\"A :\")\n",
    "\n",
    "    if a_idx != -1:\n",
    "        q_part = text[:a_idx].strip()\n",
    "        a_part = text[a_idx:].strip()\n",
    "        # A : 제거\n",
    "        a_part = re.sub(r\"^A\\s*:\\s*\", \"\", a_part, flags=re.MULTILINE).strip()\n",
    "    else:\n",
    "        q_idx = text.find(\"Q :\")\n",
    "        if q_idx != -1:\n",
    "            q_part = text[q_idx:].strip()\n",
    "            a_part = \"\"\n",
    "        else:\n",
    "\n",
    "            q_part, a_part = text, \"\"\n",
    "\n",
    "    # Q : / 제목 : 제거\n",
    "    q_part = re.sub(r\"^제목\\s*:\\s*\", \"\", q_part, flags=re.MULTILINE)\n",
    "    q_part = re.sub(r\"^Q\\s*:\\s*\", \"\", q_part, flags=re.MULTILINE)\n",
    "\n",
    "    q_part = clean_text(q_part)\n",
    "    a_part = clean_text(a_part)\n",
    "    return q_part, a_part\n",
    "\n",
    "\n",
    "def load_wide_from_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    중앙행정기관.csv → wide 포맷으로 피벗.\n",
    "    complaint_text 컬럼에 원본 질의+답변 전체가 들어있다고 가정.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    group_keys = [\"source\", \"consulting_date\", \"consulting_category\", \"consulting_content\"]\n",
    "\n",
    "    wide = (\n",
    "        df.pivot_table(\n",
    "            index=group_keys,\n",
    "            columns=\"classification_category\",\n",
    "            values=\"classification\",\n",
    "            aggfunc=lambda x: \" / \".join(sorted(set(x))),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    wide = wide.rename(\n",
    "        columns={\n",
    "            \"consulting_content\": \"complaint_text\",\n",
    "            \"상담 주제\": \"topic\",\n",
    "            \"상담 사유\": \"reason\",\n",
    "            \"상담 결과\": \"outcome\",\n",
    "            \"상담 요건\": \"requirement\",\n",
    "            \"상담 내용\": \"summary\",\n",
    "        }\n",
    "    )\n",
    "    return wide\n",
    "\n",
    "\n",
    "def build_qa_dataset_from_wide(wide: pd.DataFrame) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    wide['complaint_text']에서 Q/A 추출.\n",
    "    - parse_question_answer()를 사용하므로 기존 전처리와 동일한 로직.\n",
    "    리턴: [{\"question\": q, \"answer\": a}, ...]\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _, row in wide.iterrows():\n",
    "        full_text = row.get(\"complaint_text\", \"\")\n",
    "        q, a = parse_question_answer(full_text)\n",
    "\n",
    "        if len(q) < 5 or len(a) < 5:\n",
    "            continue\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"question\": q,\n",
    "                \"answer\": a,\n",
    "                \"topic\": row.get(\"topic\", \"\"),\n",
    "                \"reason\": row.get(\"reason\", \"\"),\n",
    "                \"outcome\": row.get(\"outcome\", \"\"),\n",
    "                \"requirement\": row.get(\"requirement\", \"\"),\n",
    "                \"summary\": row.get(\"summary\", \"\"),\n",
    "            }\n",
    "        )\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_train_val_test(\n",
    "    all_data: List[Dict[str, str]],\n",
    "    val_ratio: float = 0.1,\n",
    "    test_ratio: float = 0.1,\n",
    "    seed: int = 42,\n",
    ") -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    all_data를 train / val / test로 분리.\n",
    "    순서를 섞은 뒤 비율대로 잘라서 사용.\n",
    "    \"\"\"\n",
    "    n = len(all_data)\n",
    "    if n == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    val_size = int(n * val_ratio)\n",
    "    test_size = int(n * test_ratio)\n",
    "\n",
    "    val_idx = idx[:val_size]\n",
    "    test_idx = idx[val_size : val_size + test_size]\n",
    "    train_idx = idx[val_size + test_size :]\n",
    "\n",
    "    def pick(idxs):\n",
    "        return [all_data[i] for i in idxs]\n",
    "\n",
    "    return pick(train_idx), pick(val_idx), pick(test_idx)\n",
    "\n",
    "\n",
    "# ---- 1) Generator LoRA 하이퍼파라미터 ----\n",
    "\n",
    "GEN_BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "GEN_LORA_OUT_DIR = \"./gen_lora\"\n",
    "BASE_SYS_PROMPT = (\n",
    "    \"당신은 한국 공공기관의 민원 답변을 작성하는 공무원 보조 AI입니다. \"\n",
    "    \"법령과 정책에 기반하여 답변하고, 실제 처리 여부는 담당 부서의 최종 판단에 따름을 명시해야 합니다.\"\n",
    ")\n",
    "\n",
    "MAX_LEN_GEN = 512\n",
    "GEN_BATCH_SIZE = 4\n",
    "GEN_NUM_EPOCHS = 3\n",
    "GEN_LR = 5e-5\n",
    "GEN_LOG_STEPS = 100\n",
    "\n",
    "\n",
    "# ---- 2) SFT Dataset ----\n",
    "\n",
    "class GeneratorSFTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generator SFT용 Dataset\n",
    "    prompt = system + question\n",
    "    target = answer 전체 (teacher forcing)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_length=512, base_sys_prompt=\"\"):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.base_sys_prompt = base_sys_prompt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        q = item[\"question\"]\n",
    "        a = item[\"answer\"]\n",
    "\n",
    "        prompt = (\n",
    "            f\"<|system|>\\n{self.base_sys_prompt}\\n\\n\"\n",
    "            f\"<|user|>\\n{q}\\n\\n\"\n",
    "            f\"<|assistant|>\\n\"\n",
    "        )\n",
    "        full_text = prompt + a\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            full_text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = enc[\"input_ids\"][0]\n",
    "        attention_mask = enc[\"attention_mask\"][0]\n",
    "        labels = input_ids.clone()  # causal LM\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "\n",
    "# ---- 3) LoRA 학습 함수 (train + val 평가) ----\n",
    "\n",
    "def train_lora_generator_with_eval(\n",
    "    train_data: List[Dict[str, str]],\n",
    "    val_data: List[Dict[str, str]],\n",
    "    output_dir: str = GEN_LORA_OUT_DIR,\n",
    "    base_model_name: str = GEN_BASE_MODEL,\n",
    "    base_sys_prompt: str = BASE_SYS_PROMPT,\n",
    "    max_length: int = MAX_LEN_GEN,\n",
    "    batch_size: int = GEN_BATCH_SIZE,\n",
    "    num_epochs: int = GEN_NUM_EPOCHS,\n",
    "    lr: float = GEN_LR,\n",
    "):\n",
    "    # 1) tokenizer, base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    # 2) LoRA 래핑\n",
    "    peft_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "    print(\n",
    "        \"[Generator] LoRA trainable params:\",\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
    "    )\n",
    "\n",
    "    # 3) Dataset 구성\n",
    "    train_dataset = GeneratorSFTDataset(\n",
    "        train_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        base_sys_prompt=base_sys_prompt,\n",
    "    )\n",
    "    val_dataset = GeneratorSFTDataset(\n",
    "        val_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        base_sys_prompt=base_sys_prompt,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,\n",
    "    )\n",
    "\n",
    "    # 4) TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=lr,\n",
    "        logging_steps=GEN_LOG_STEPS,\n",
    "        save_strategy=\"epoch\", \n",
    "        bf16=True,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    # 5) Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,   # val 데이터로 eval\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    # 6) 학습\n",
    "    trainer.train()\n",
    "\n",
    "    # 7) 학습 후 val set 평가\n",
    "    metrics = trainer.evaluate()\n",
    "    print(\"[Generator] Eval metrics:\", metrics)\n",
    "    if \"eval_loss\" in metrics:\n",
    "        try:\n",
    "            ppl = math.exp(metrics[\"eval_loss\"])\n",
    "            print(f\"[Generator] Eval Perplexity ≈ {ppl:.3f}\")\n",
    "        except OverflowError:\n",
    "            print(\"[Generator] Perplexity 계산 실패 (loss가 너무 큼).\")\n",
    "\n",
    "    # 8) LoRA + tokenizer 저장 (마지막 상태)\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"[Generator LoRA] Saved to {output_dir}\")\n",
    "\n",
    "\n",
    "# ---- 4) main: 전체 플로우 ----\n",
    "\n",
    "def main():\n",
    "    # 1) CSV 로드\n",
    "    csv_path = \"data/중앙행정기관.csv\" \n",
    "    wide = load_wide_from_csv(csv_path)\n",
    "\n",
    "    # 2) Q/A 추출\n",
    "    qa_data = build_qa_dataset_from_wide(wide)\n",
    "    print(f\"총 Q/A 개수: {len(qa_data)}\")\n",
    "    if len(qa_data) < 50:\n",
    "        print(\"Q/A가 너무 적음. CSV/파싱 로직 다시 확인 필요.\")\n",
    "        return\n",
    "\n",
    "    # 3) train/val/test 분리\n",
    "    train_data, val_data, test_data = split_train_val_test(\n",
    "        qa_data,\n",
    "        val_ratio=0.1,\n",
    "        test_ratio=0.1,\n",
    "        seed=42,\n",
    "    )\n",
    "    print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "    # 4) LoRA 학습 (train으로 학습, val로 검증)\n",
    "    train_lora_generator_with_eval(\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        output_dir=GEN_LORA_OUT_DIR,\n",
    "        base_model_name=GEN_BASE_MODEL,\n",
    "        base_sys_prompt=BASE_SYS_PROMPT,\n",
    "        max_length=MAX_LEN_GEN,\n",
    "        batch_size=GEN_BATCH_SIZE,\n",
    "        num_epochs=GEN_NUM_EPOCHS,\n",
    "        lr=GEN_LR,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c6b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Generator] LoRA loaded from ./gen_lora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Verifier] LoRA not found. Using base model only.\n",
      "=== 민원 질문 입력 (종료: 빈 줄 + 엔터) ===\n",
      "\n",
      "[선택된 전략] 해결책 제안형\n",
      "\n",
      "[답변]\n",
      " [첨단 태양광 기술 및 노동 전문 업체]\n",
      "\n",
      "[민원 내용]\n",
      "\n",
      "현황 및 문제점 교량주변은 밤에도 밝아서 산책하기에 좋고 미적으로도 아름다움을 주지만 교량밑은 어둡고 컴컴해 위험하고 또 칙칙하다는 느낌을 주기도 해 경관 상 안좋다는 문제가 있다 개선방안 교량밑에 미디어아트 설치한다 기대효과 시각적 효과 상승 및 미적경관 향상\n",
      "\n",
      "[추가 지침]\n",
      "- 관련 법령/정책과의 일치성을 확인하고, 처리 가능/불가능을 명확히 구분하세요.\n",
      "- 민원인이 이해하기 쉬운 구조로 답변하고, 필요한 경우 대안/절차를 제시하세요.\n",
      "- 과도한 약속이나 확정적인 표현은 피하고, '담당 부서의 최종 판단'이 필요함을 밝혀주세요.\n",
      "\n",
      "[민원 내용\n",
      "\n",
      "[Meta-Reward] 0.524\n",
      "\n",
      "[밴딧 전략 상태]\n",
      "  [법률-정책 최우선] 예상 성공도 ≈ 0.500 | feature=[0.9 0.6 0.4 0.8 0.7] | 설명: 법령, 조례, 내부지침과의 일치성을 최우선으로 하고 책임 범위를 분명히 하는 보수적 답변.\n",
      "  [민원인 공감형] 예상 성공도 ≈ 0.500 | feature=[0.6 0.7 0.9 0.3 0.5] | 설명: 민원인의 감정과 상황을 공감하며, 이해하기 쉬운 언어로 절차와 한계를 설명.\n",
      "  [해결책 제안형] 예상 성공도 ≈ 0.500 | feature=[0.7 0.9 0.7 0.4 0.8] | 설명: 현실적으로 가능한 대안과 행동 옵션을 최대한 제시하는 해결 중심 답변.\n",
      "종료합니다.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1500979195.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-1500979195.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0minteractive_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0mdf_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_data.csv'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. 기본 import\n",
    "# ============================================================\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "# ============================================================\n",
    "# 1. Bandit용 Arm 정의 + UCB 로지스틱 밴딧\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class PromptArmConfig:\n",
    "    name: str\n",
    "    description: str\n",
    "    feature_vector: np.ndarray  # shape = (d,)\n",
    "\n",
    "\n",
    "class LogisticPromptBandit:\n",
    "    \"\"\"\n",
    "    프롬프트 전략 선택용 logistic bandit (UCB).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        lambda_reg: float = 1.0,\n",
    "        eta: float = 0.1,\n",
    "        beta: float = 1.0,\n",
    "    ):\n",
    "        self.arms = arms\n",
    "        self.n_arms = len(arms)\n",
    "        self.d = arms[0].feature_vector.shape[0]\n",
    "\n",
    "        # arm별 파라미터 w, 정보 행렬 H\n",
    "        self.w = np.zeros((self.n_arms, self.d))\n",
    "        self.H = [lambda_reg * np.eye(self.d) for _ in range(self.n_arms)]\n",
    "\n",
    "        self.eta = eta\n",
    "        self.beta = beta\n",
    "\n",
    "    def _sigmoid(self, z: float) -> float:\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def select_arm(self) -> int:\n",
    "        \"\"\"\n",
    "        UCB 기반 arm 선택\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = arm.feature_vector\n",
    "            mean = float(self.w[a_idx].dot(x))\n",
    "            invH = np.linalg.inv(self.H[a_idx])\n",
    "            var = float(x.T @ invH @ x)\n",
    "            ucb = self.beta * np.sqrt(max(var, 1e-12))\n",
    "            scores.append(mean + ucb)\n",
    "        return int(np.argmax(scores))\n",
    "\n",
    "    def update(self, arm_idx: int, reward: float):\n",
    "        \"\"\"\n",
    "        선택한 arm에 대해 로지스틱 회귀 gradient 업데이트\n",
    "        \"\"\"\n",
    "        x = self.arms[arm_idx].feature_vector\n",
    "        z = float(self.w[arm_idx].dot(x))\n",
    "        p = self._sigmoid(z)  # 예측 성공 확률\n",
    "\n",
    "        grad = -(reward - p) * x  # 로지스틱 회귀 gradient\n",
    "        self.H[arm_idx] += np.outer(x, x)\n",
    "        invH = np.linalg.inv(self.H[arm_idx])\n",
    "        step = self.eta * (invH @ grad)\n",
    "        self.w[arm_idx] -= step\n",
    "\n",
    "    def explain_current_strategy(self) -> List[str]:\n",
    "        lines = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = arm.feature_vector\n",
    "            z = float(self.w[a_idx].dot(x))\n",
    "            p = self._sigmoid(z)\n",
    "            lines.append(\n",
    "                f\"[{arm.name}] 예상 성공도 ≈ {p:.3f} | \"\n",
    "                f\"feature={np.round(x, 2)} | 설명: {arm.description}\"\n",
    "            )\n",
    "        return lines\n",
    "\n",
    "\n",
    "def build_default_arms() -> List[PromptArmConfig]:\n",
    "    \"\"\"\n",
    "    기본 3가지 전략 프로필 정의\n",
    "    \"\"\"\n",
    "    return [\n",
    "        PromptArmConfig(\n",
    "            name=\"법률-정책 최우선\",\n",
    "            description=\"법령, 조례, 내부지침과의 일치성을 최우선으로 하고 책임 범위를 분명히 하는 보수적 답변.\",\n",
    "            feature_vector=np.array([0.9, 0.6, 0.4, 0.8, 0.7]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"민원인 공감형\",\n",
    "            description=\"민원인의 감정과 상황을 공감하며, 이해하기 쉬운 언어로 절차와 한계를 설명.\",\n",
    "            feature_vector=np.array([0.6, 0.7, 0.9, 0.3, 0.5]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"해결책 제안형\",\n",
    "            description=\"현실적으로 가능한 대안과 행동 옵션을 최대한 제시하는 해결 중심 답변.\",\n",
    "            feature_vector=np.array([0.7, 0.9, 0.7, 0.4, 0.8]),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. 시스템 프롬프트 + arm 기반 user 프롬프트 구성\n",
    "# ============================================================\n",
    "\n",
    "BASE_SYS_PROMPT = (\n",
    "    \"당신은 한국 공공기관의 민원 처리 보조 AI입니다. \"\n",
    "    \"사실과 법령에 기반해 답변하고, 정책과 조례를 임의로 확대 해석하지 마세요. \"\n",
    "    \"항상 처리 가능 범위와 한계를 분명히 설명하고, \"\n",
    "    \"답변 마지막에는 '실제 처리 여부는 담당 부서의 최종 판단에 따릅니다.'라고 명시하세요.\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_prompt_from_arm(complaint_text: str, arm: PromptArmConfig) -> str:\n",
    "    return (\n",
    "        f\"아래 민원에 대해 답변을 작성하되, 다음 전략 프로필을 따르세요.\\n\\n\"\n",
    "        f\"[전략 이름]\\n{arm.name}\\n\\n\"\n",
    "        f\"[전략 설명]\\n{arm.description}\\n\\n\"\n",
    "        f\"[민원 내용]\\n{complaint_text}\\n\\n\"\n",
    "        f\"[추가 지침]\\n\"\n",
    "        f\"- 관련 법령/정책과의 일치성을 확인하고, 처리 가능/불가능을 명확히 구분하세요.\\n\"\n",
    "        f\"- 민원인이 이해하기 쉬운 구조로 답변하고, 필요한 경우 대안/절차를 제시하세요.\\n\"\n",
    "        f\"- 과도한 약속이나 확정적인 표현은 피하고, '담당 부서의 최종 판단'이 필요함을 밝혀주세요.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Generator 래퍼 (TinyLlama + LoRA)\n",
    "# ============================================================\n",
    "\n",
    "class LlamaGeneratorWrapper:\n",
    "    def __init__(self, base_model_name: str, lora_dir: Optional[str] = None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "        if lora_dir is not None and os.path.isdir(lora_dir):\n",
    "            model = PeftModel.from_pretrained(model, lora_dir)\n",
    "            print(f\"[Generator] LoRA loaded from {lora_dir}\")\n",
    "        else:\n",
    "            print(\"[Generator] LoRA not found. Using base model only.\")\n",
    "\n",
    "        self.pipe = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "    def generate(self, system_prompt: str, user_prompt: str, max_new_tokens: int = 512) -> str:\n",
    "        \"\"\"\n",
    "        Chat-style 입력으로 TinyLlama 호출\n",
    "        \"\"\"\n",
    "        msgs = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "\n",
    "        out = self.pipe(\n",
    "            msgs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.3,\n",
    "            top_p=0.9,\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        # 일부 버전에서는 generated_text가 message list일 수 있음\n",
    "        if isinstance(out, list):\n",
    "            for m in out:\n",
    "                if isinstance(m, dict) and m.get(\"role\") == \"assistant\":\n",
    "                    return m.get(\"content\", \"\").strip()\n",
    "        return str(out)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Verifier 래퍼 (DistilBERT + LoRA(optional))\n",
    "# ============================================================\n",
    "\n",
    "class VerifierWrapper:\n",
    "    \"\"\"\n",
    "    (질문, 답변) → [0,1] 품질 점수\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_model_name: str, lora_dir: Optional[str] = None, device: str = \"cpu\"):\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            base_model_name,\n",
    "            num_labels=1,\n",
    "            problem_type=\"regression\",\n",
    "            torch_dtype=torch.float32 if device == \"cpu\" else torch.bfloat16,\n",
    "        )\n",
    "\n",
    "        if lora_dir is not None and os.path.isdir(lora_dir):\n",
    "            model = PeftModel.from_pretrained(model, lora_dir)\n",
    "            print(f\"[Verifier] LoRA loaded from {lora_dir}\")\n",
    "        else:\n",
    "            print(\"[Verifier] LoRA not found. Using base model only.\")\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, complaint: str, answer: str) -> float:\n",
    "        text = f\"[COMPLAINT]\\n{complaint}\\n\\n[ANSWER]\\n{answer}\"\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**enc).logits\n",
    "        score = torch.sigmoid(logits)[0].item()  # [0,1]로 squash\n",
    "        return float(max(0.0, min(1.0, score)))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. (간단 버전) MetaVerifier: LM 점수 + 전략 일치도\n",
    "# ============================================================\n",
    "\n",
    "class MetaVerifier:\n",
    "    \"\"\"\n",
    "    - LM 기반 품질 점수: f_lm(Q, A)\n",
    "    - 전략 일치도 점수: f_arm(A, arm)\n",
    "    을 합쳐서 최종 reward 반환.\n",
    "    (클러스터 기반 평가는 완전 온라인 모드에서는 사용 안 함)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lm_verifier: VerifierWrapper):\n",
    "        self.lm_verifier = lm_verifier\n",
    "\n",
    "    def _arm_alignment(self, answer: str, arm: PromptArmConfig) -> float:\n",
    "        \"\"\"\n",
    "        arm 전략과 답변 내용이 얼추 맞는지 간단한 키워드 매칭으로 평가.\n",
    "        \"\"\"\n",
    "        txt = answer[:2000]\n",
    "\n",
    "        if \"법률-정책 최우선\" in arm.name:\n",
    "            keywords = [\"법\", \"조항\", \"시행령\", \"조례\", \"규정\"]\n",
    "        elif \"공감형\" in arm.name:\n",
    "            keywords = [\"이해\", \"불편을 드려\", \"죄송\", \"공감\", \"도움이 되셨으면\"]\n",
    "        elif \"해결책 제안형\" in arm.name:\n",
    "            keywords = [\"대안\", \"조치\", \"절차\", \"신청\", \"문의\", \"방법\"]\n",
    "        else:\n",
    "            keywords = []\n",
    "\n",
    "        if not keywords:\n",
    "            return 0.5\n",
    "\n",
    "        hit = sum(1 for kw in keywords if kw in txt)\n",
    "        return max(0.3, min(1.0, hit / max(1, len(keywords))))\n",
    "\n",
    "    def evaluate(self, question: str, answer: str, arm: PromptArmConfig) -> float:\n",
    "        # 1) LM 기반 품질\n",
    "        s_lm = self.lm_verifier.evaluate(question, answer)\n",
    "\n",
    "        # 2) 전략 일치도\n",
    "        s_arm = self._arm_alignment(answer, arm)\n",
    "\n",
    "        # 3) (옵션) 클러스터 일관성은 완전 온라인 모드에서는 사용 X → 상수로 둠\n",
    "        s_cluster = 0.7\n",
    "\n",
    "        reward = (\n",
    "            0.5 * s_lm +\n",
    "            0.3 * s_cluster +\n",
    "            0.2 * s_arm\n",
    "        )\n",
    "        return float(max(0.0, min(1.0, reward)))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. 질문 정제 stub (나중에 TinyLlama로 개선 가능)\n",
    "# ============================================================\n",
    "\n",
    "def refine_question_with_cluster_hints(\n",
    "    raw_question: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    완전 온라인 버전에서는 일단 그대로 반환.\n",
    "    (원하면 여기서 '질문 요약/구조화'용 LLM 한 번 더 태울 수 있음)\n",
    "    \"\"\"\n",
    "    return raw_question.strip()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. PromptBanditEngine: 전체 파이프라인 묶기\n",
    "# ============================================================\n",
    "\n",
    "class PromptBanditEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        generator: LlamaGeneratorWrapper,\n",
    "        lm_verifier: VerifierWrapper,\n",
    "    ):\n",
    "        self.bandit = LogisticPromptBandit(arms=arms)\n",
    "        self.generator = generator\n",
    "        self.meta_verifier = MetaVerifier(lm_verifier=lm_verifier)\n",
    "\n",
    "    def step(self, raw_complaint: str) -> Dict[str, Any]:\n",
    "        # 1) bandit으로 arm 선택\n",
    "        arm_idx = self.bandit.select_arm()\n",
    "        arm = self.bandit.arms[arm_idx]\n",
    "\n",
    "        # 2) (옵션) 질문 정제\n",
    "        refined_q = refine_question_with_cluster_hints(raw_complaint)\n",
    "\n",
    "        # 3) 프롬프트 생성 + 답변\n",
    "        user_prompt = build_prompt_from_arm(refined_q, arm)\n",
    "        answer = self.generator.generate(BASE_SYS_PROMPT, user_prompt)\n",
    "\n",
    "        # 4) 메타-verifier로 reward 계산\n",
    "        reward = self.meta_verifier.evaluate(refined_q, answer, arm)\n",
    "\n",
    "        # 5) bandit 업데이트\n",
    "        self.bandit.update(arm_idx, reward)\n",
    "\n",
    "        return {\n",
    "            \"arm_idx\": arm_idx,\n",
    "            \"arm_name\": arm.name,\n",
    "            \"arm_description\": arm.description,\n",
    "            \"question\": refined_q,\n",
    "            \"answer\": answer,\n",
    "            \"reward\": reward,\n",
    "            \"strategy_view\": self.bandit.explain_current_strategy(),\n",
    "        }\n",
    "\n",
    "def evaluate_batch(engine: PromptBanditEngine, test_data, out_csv=\"batch_results.csv\"):\n",
    "    logs = []\n",
    "    for item in test_data:\n",
    "        q = item[\"question\"]\n",
    "        out = engine.step(q)\n",
    "        logs.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": out[\"answer\"],\n",
    "            \"reward\": out[\"reward\"],\n",
    "            \"arm\": out[\"arm_name\"],\n",
    "        })\n",
    "    df = pd.DataFrame(logs)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. 인터랙티브 루프 + 온라인 엔진 빌더\n",
    "# ============================================================\n",
    "\n",
    "def interactive_loop(engine: PromptBanditEngine):\n",
    "    \"\"\"\n",
    "    터미널/Colab에서 바로 돌리는 인터랙티브 모드\n",
    "    \"\"\"\n",
    "    print(\"=== 민원 질문 입력 (종료: 빈 줄 + 엔터) ===\")\n",
    "    while True:\n",
    "        q = input(\"\\n[민원] > \").strip()\n",
    "        if not q:\n",
    "            print(\"종료합니다.\")\n",
    "            break\n",
    "\n",
    "        out = engine.step(q)\n",
    "\n",
    "        print(f\"\\n[선택된 전략] {out['arm_name']}\")\n",
    "        print(\"\\n[답변]\\n\", out[\"answer\"][:2000])\n",
    "        print(f\"\\n[Meta-Reward] {out['reward']:.3f}\")\n",
    "        print(\"\\n[밴딧 전략 상태]\")\n",
    "        for line in out[\"strategy_view\"]:\n",
    "            print(\" \", line)\n",
    "\n",
    "\n",
    "def build_online_engine(\n",
    "    gen_base_model: str = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    gen_lora_dir: str = \"./gen_lora\",\n",
    "    ver_base_model: str = \"distilbert-base-multilingual-cased\",\n",
    "    ver_lora_dir: str = \"./verifier_lora\",\n",
    "    device: str = \"cpu\",\n",
    ") -> PromptBanditEngine:\n",
    "    \"\"\"\n",
    "    완전 온라인 서비스용 엔진 빌드 함수\n",
    "    (학습된 LoRA 디렉토리만 있으면 바로 사용)\n",
    "    \"\"\"\n",
    "    generator = LlamaGeneratorWrapper(\n",
    "        base_model_name=gen_base_model,\n",
    "        lora_dir=gen_lora_dir,\n",
    "    )\n",
    "    verifier = VerifierWrapper(\n",
    "        base_model_name=ver_base_model,\n",
    "        lora_dir=ver_lora_dir,\n",
    "        device=device,\n",
    "    )\n",
    "    arms = build_default_arms()\n",
    "    engine = PromptBanditEngine(\n",
    "        arms=arms,\n",
    "        generator=generator,\n",
    "        lm_verifier=verifier,\n",
    "    )\n",
    "    return engine\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. main: 완전 온라인 서비스 entry point\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    - ./gen_lora 에서 Generator LoRA 불러옴\n",
    "    - ./verifier_lora 가 있으면 Verifier LoRA도 같이 로드 (없으면 base만)\n",
    "    - 이후 인터랙티브 루프 실행\n",
    "    \"\"\"\n",
    "    engine = build_online_engine(\n",
    "        gen_base_model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "        gen_lora_dir=\"./gen_lora\",\n",
    "        ver_base_model=\"distilbert-base-multilingual-cased\",\n",
    "        ver_lora_dir=\"./verifier_lora\",\n",
    "        device=\"cpu\",  \n",
    "    )\n",
    "    interactive_loop(engine)\\\n",
    "    \n",
    "    test_df = pd.read_csv(\"test_data.csv\")\n",
    "    df_res = evaluate_batch(engine, test_df)\n",
    "    print(df_res.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d82dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /content/complaint_system_AI\n",
      "['system_test.ipynb', 'Complaint data.zip', 'data', 'complain_data.zip', 'gen_lora', 'complain_quality_shap.py', '.git', 'README.md', 'gen_lora.zip', 'bandit_prompt_system.py']\n",
      "\n",
      "[gen_lora 내용]\n",
      "['tokenizer_config.json', 'checkpoint-1780', 'checkpoint-890', 'chat_template.jinja', 'tokenizer.model', 'tokenizer.json', 'adapter_config.json', 'special_tokens_map.json', 'adapter_model.safetensors', 'README.md', 'checkpoint-2670']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/content/complaint_system_AI\")\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(os.listdir(\".\"))\n",
    "print(\"\\n[gen_lora 내용]\")\n",
    "print(os.listdir(\"gen_lora\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fc4ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f gen_lora.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f97323eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/complaint_system_AI\n",
      "  adding: gen_lora/ (stored 0%)\n",
      "  adding: gen_lora/tokenizer_config.json (deflated 69%)\n",
      "  adding: gen_lora/checkpoint-1780/ (stored 0%)\n",
      "  adding: gen_lora/checkpoint-1780/tokenizer_config.json (deflated 69%)\n",
      "  adding: gen_lora/checkpoint-1780/training_args.bin (deflated 53%)\n",
      "  adding: gen_lora/checkpoint-1780/scheduler.pt (deflated 61%)\n",
      "  adding: gen_lora/checkpoint-1780/trainer_state.json (deflated 72%)\n",
      "  adding: gen_lora/checkpoint-1780/chat_template.jinja (deflated 60%)\n",
      "  adding: gen_lora/checkpoint-1780/tokenizer.model (deflated 55%)\n",
      "  adding: gen_lora/checkpoint-1780/tokenizer.json (deflated 85%)\n",
      "  adding: gen_lora/checkpoint-1780/adapter_config.json (deflated 57%)\n",
      "  adding: gen_lora/checkpoint-1780/rng_state.pth (deflated 26%)\n",
      "  adding: gen_lora/checkpoint-1780/special_tokens_map.json (deflated 79%)\n",
      "  adding: gen_lora/checkpoint-1780/adapter_model.safetensors (deflated 8%)\n",
      "  adding: gen_lora/checkpoint-1780/optimizer.pt (deflated 8%)\n",
      "  adding: gen_lora/checkpoint-1780/README.md (deflated 66%)\n",
      "  adding: gen_lora/checkpoint-890/ (stored 0%)\n",
      "  adding: gen_lora/checkpoint-890/tokenizer_config.json (deflated 69%)\n",
      "  adding: gen_lora/checkpoint-890/training_args.bin (deflated 53%)\n",
      "  adding: gen_lora/checkpoint-890/scheduler.pt (deflated 61%)\n",
      "  adding: gen_lora/checkpoint-890/trainer_state.json (deflated 67%)\n",
      "  adding: gen_lora/checkpoint-890/chat_template.jinja (deflated 60%)\n",
      "  adding: gen_lora/checkpoint-890/tokenizer.model (deflated 55%)\n",
      "  adding: gen_lora/checkpoint-890/tokenizer.json (deflated 85%)\n",
      "  adding: gen_lora/checkpoint-890/adapter_config.json (deflated 57%)\n",
      "  adding: gen_lora/checkpoint-890/rng_state.pth (deflated 26%)\n",
      "  adding: gen_lora/checkpoint-890/special_tokens_map.json (deflated 79%)\n",
      "  adding: gen_lora/checkpoint-890/adapter_model.safetensors (deflated 8%)\n",
      "  adding: gen_lora/checkpoint-890/optimizer.pt (deflated 8%)\n",
      "  adding: gen_lora/checkpoint-890/README.md (deflated 66%)\n",
      "  adding: gen_lora/chat_template.jinja (deflated 60%)\n",
      "  adding: gen_lora/tokenizer.model (deflated 55%)\n",
      "  adding: gen_lora/tokenizer.json (deflated 85%)\n",
      "  adding: gen_lora/adapter_config.json (deflated 57%)\n",
      "  adding: gen_lora/special_tokens_map.json (deflated 79%)\n",
      "  adding: gen_lora/adapter_model.safetensors (deflated 8%)\n",
      "  adding: gen_lora/README.md (deflated 66%)\n",
      "  adding: gen_lora/checkpoint-2670/ (stored 0%)\n",
      "  adding: gen_lora/checkpoint-2670/tokenizer_config.json (deflated 69%)\n",
      "  adding: gen_lora/checkpoint-2670/training_args.bin (deflated 53%)\n",
      "  adding: gen_lora/checkpoint-2670/scheduler.pt (deflated 61%)\n",
      "  adding: gen_lora/checkpoint-2670/trainer_state.json (deflated 75%)\n",
      "  adding: gen_lora/checkpoint-2670/chat_template.jinja (deflated 60%)\n",
      "  adding: gen_lora/checkpoint-2670/tokenizer.model (deflated 55%)\n",
      "  adding: gen_lora/checkpoint-2670/tokenizer.json (deflated 85%)\n",
      "  adding: gen_lora/checkpoint-2670/adapter_config.json (deflated 57%)\n",
      "  adding: gen_lora/checkpoint-2670/rng_state.pth (deflated 26%)\n",
      "  adding: gen_lora/checkpoint-2670/special_tokens_map.json (deflated 79%)\n",
      "  adding: gen_lora/checkpoint-2670/adapter_model.safetensors (deflated 8%)\n",
      "  adding: gen_lora/checkpoint-2670/optimizer.pt (deflated 8%)\n",
      "  adding: gen_lora/checkpoint-2670/README.md (deflated 66%)\n"
     ]
    }
   ],
   "source": [
    "%cd /content/complaint_system_AI\n",
    "!zip -r gen_lora.zip gen_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e61a18b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 83M Dec  1 16:45 gen_lora.zip\n"
     ]
    }
   ],
   "source": [
    "!ls -lh gen_lora.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f51f8566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 83M Dec  1 16:45 /content/complaint_system_AI/gen_lora.zip\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /content/complaint_system_AI/gen_lora.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16721c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 110084\n",
      "drwxr-xr-x 5 root root     4096 Dec  1 16:18  .\n",
      "drwxr-xr-x 1 root root     4096 Dec  1 12:11  ..\n",
      "-rw-r--r-- 1 root root    17137 Dec  1 12:12  bandit_prompt_system.py\n",
      "-rw-r--r-- 1 root root 13075801 Dec  1 12:12  complain_data.zip\n",
      "-rw-r--r-- 1 root root    15137 Dec  1 12:12  complain_quality_shap.py\n",
      "-rw-r--r-- 1 root root 13075801 Dec  1 12:12 'Complaint data.zip'\n",
      "drwxr-xr-x 2 root root     4096 Dec  1 12:12  data\n",
      "drwxr-xr-x 5 root root     4096 Dec  1 15:53  gen_lora\n",
      "-rw-r--r-- 1 root root 86402045 Dec  1 16:18  gen_lora.zip\n",
      "drwxr-xr-x 8 root root     4096 Dec  1 12:12  .git\n",
      "-rw-r--r-- 1 root root      978 Dec  1 12:12  README.md\n",
      "-rw-r--r-- 1 root root    98443 Dec  1 12:12  system_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -al /content/complaint_system_AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fc99795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/content/complaint_system_AI/gen_lora.zip' target='_blank'>/content/complaint_system_AI/gen_lora.zip</a><br>"
      ],
      "text/plain": [
       "/content/complaint_system_AI/gen_lora.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import FileLink, display\n",
    "\n",
    "zip_path = \"/content/complaint_system_AI/gen_lora.zip\"\n",
    "display(FileLink(zip_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abe000d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /content/complaint_system_AI\n",
      "\n",
      "[현재 폴더 내용]\n",
      "['system_test.ipynb', 'Complaint data.zip', 'data', 'complain_data.zip', 'gen_lora', 'complain_quality_shap.py', '.git', 'README.md', 'gen_lora.zip', 'bandit_prompt_system.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "print(\"\\n[현재 폴더 내용]\")\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cbf0b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/complaint_system_AI'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca0708bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /content/complaint_system_AI\n",
      "gen_lora.zip exists? -> True\n",
      "total 8.0K\n",
      "drwxr-xr-x 5 root root 4.0K Dec  1 16:45 complaint_system_AI\n",
      "drwxr-xr-x 1 root root 4.0K Nov 20 14:30 sample_data\n",
      "total 108M\n",
      "-rw-r--r-- 1 root root  17K Dec  1 12:12  bandit_prompt_system.py\n",
      "-rw-r--r-- 1 root root  13M Dec  1 12:12  complain_data.zip\n",
      "-rw-r--r-- 1 root root  15K Dec  1 12:12  complain_quality_shap.py\n",
      "-rw-r--r-- 1 root root  13M Dec  1 12:12 'Complaint data.zip'\n",
      "drwxr-xr-x 2 root root 4.0K Dec  1 12:12  data\n",
      "drwxr-xr-x 5 root root 4.0K Dec  1 15:53  gen_lora\n",
      "-rw-r--r-- 1 root root  83M Dec  1 16:45  gen_lora.zip\n",
      "-rw-r--r-- 1 root root  978 Dec  1 12:12  README.md\n",
      "-rw-r--r-- 1 root root  97K Dec  1 12:12  system_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"gen_lora.zip exists? ->\", os.path.exists(\"/content/complaint_system_AI/gen_lora.zip\"))\n",
    "!ls -lh /content\n",
    "!ls -lh /content/complaint_system_AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4117bcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('google.colab' in sys.modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "409aba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google.colab in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
      "Requirement already satisfied: google-auth==2.43.0 in /usr/local/lib/python3.12/dist-packages (from google.colab) (2.43.0)\n",
      "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.12/dist-packages (from google.colab) (6.17.1)\n",
      "Requirement already satisfied: ipyparallel==8.8.0 in /usr/local/lib/python3.12/dist-packages (from google.colab) (8.8.0)\n",
      "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.12/dist-packages (from google.colab) (7.34.0)\n",
      "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (from google.colab) (2.2.2)\n",
      "Requirement already satisfied: jupyter-server==2.14.0 in /usr/local/lib/python3.12/dist-packages (from google.colab) (2.14.0)\n",
      "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.12/dist-packages (from google.colab) (1.5.2)\n",
      "Requirement already satisfied: requests==2.32.4 in /usr/local/lib/python3.12/dist-packages (from google.colab) (2.32.4)\n",
      "Requirement already satisfied: tornado==6.5.1 in /usr/local/lib/python3.12/dist-packages (from google.colab) (6.5.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth==2.43.0->google.colab) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth==2.43.0->google.colab) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth==2.43.0->google.colab) (4.9.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (1.8.15)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (7.4.9)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (1.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (26.2.1)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel==6.17.1->google.colab) (5.7.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipyparallel==8.8.0->google.colab) (4.4.2)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from ipyparallel==8.8.0->google.colab) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.12/dist-packages (from ipyparallel==8.8.0->google.colab) (2.9.0.post0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ipyparallel==8.8.0->google.colab) (4.67.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (75.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (0.19.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (3.0.52)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (2.19.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython==7.34.0->google.colab) (4.9.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (4.11.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (5.9.1)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server==2.14.0->google.colab) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->google.colab) (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->google.colab) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2->google.colab) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->google.colab) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->google.colab) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->google.colab) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4->google.colab) (2025.11.12)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server==2.14.0->google.colab) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server==2.14.0->google.colab) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server==2.14.0->google.colab) (25.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython==7.34.0->google.colab) (0.8.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyter-server==2.14.0->google.colab) (3.0.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server==2.14.0->google.colab) (4.5.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (4.25.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (6.0.3)\n",
      "Requirement already satisfied: referencing in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (0.37.0)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (1.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server==2.14.0->google.colab) (2.21.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython==7.34.0->google.colab) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google.colab) (0.2.14)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.43.0->google.colab) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.1->ipyparallel==8.8.0->google.colab) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (1.4.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (2025.9.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (0.29.0)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (25.10.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server==2.14.0->google.colab) (2.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server==2.14.0->google.colab) (2.8)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server==2.14.0->google.colab) (2.23)\n",
      "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (1.3.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server==2.14.0->google.colab) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50b4e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/complaint_system_AI\n",
      "origin\thttps://github.com/aivle-agent/complaint_system_AI.git (fetch)\n",
      "origin\thttps://github.com/aivle-agent/complaint_system_AI.git (push)\n",
      "On branch main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\t\u001b[31mgen_lora/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "%cd /content/complaint_system_AI\n",
    "\n",
    "!git config --global user.email \"spikasta@snu.ac.kr\"\n",
    "!git config --global user.name \"wonnowone\"\n",
    "# 혹시 git 설정 안 돼 있으면 remote 확인\n",
    "!git remote -v\n",
    "\n",
    "# zip 파일 add\n",
    "!git add gen_lora.zip\n",
    "\n",
    "# 커밋\n",
    "!git commit -m \"Add gen_lora LoRA checkpoint\"\n",
    "\n",
    "# 푸시 (브랜치 이름은 너 repo에 맞춰: main / master / 등)\n",
    "!git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc103ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# 0. 기본 import & 공통 유틸\n",
    "# =====================================================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 1. 데이터 전처리: CSV → (question, answer) 리스트\n",
    "# =====================================================================\n",
    "\n",
    "def clean_text(x: Any) -> str:\n",
    "    \"\"\"전화번호, 주민번호, 이름 패턴 등을 마스킹하고 strip.\"\"\"\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "    x = re.sub(r\"\\d{2,3}-\\d{3,4}-\\d{4}\", \"[TEL]\", x)\n",
    "    x = re.sub(r\"\\d{6}-\\d{7}\", \"[RRN]\", x)\n",
    "    x = re.sub(r\"[가-힣]{2,3}씨\", \"[NAME]\", x)\n",
    "    return x.strip()\n",
    "\n",
    "\n",
    "def parse_question_answer(full_text: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    중앙행정기관 데이터의 consulting_content에서\n",
    "    Q/A 부분을 분리한다.\n",
    "\n",
    "    대략적인 패턴:\n",
    "      \"제목 : ...\\n\\nQ : ...\\n...\\n\\nA : ...\"\n",
    "\n",
    "    Q/A 구분이 애매한 경우엔 heuristics로 처리.\n",
    "    \"\"\"\n",
    "    if not isinstance(full_text, str):\n",
    "        return \"\", \"\"\n",
    "\n",
    "    text = full_text.strip()\n",
    "\n",
    "    # 1) \"A :\" 기준으로 먼저 자르기\n",
    "    a_idx = text.find(\"\\nA :\")\n",
    "    if a_idx == -1:\n",
    "        a_idx = text.find(\"\\n\\nA :\")\n",
    "    if a_idx == -1:\n",
    "        a_idx = text.find(\"A :\")\n",
    "\n",
    "    if a_idx != -1:\n",
    "        q_part = text[:a_idx].strip()\n",
    "        a_part = text[a_idx:].strip()\n",
    "        a_part = re.sub(r\"^A\\s*:\\s*\", \"\", a_part, flags=re.MULTILINE).strip()\n",
    "    else:\n",
    "        q_idx = text.find(\"Q :\")\n",
    "        if q_idx != -1:\n",
    "            q_part = text[q_idx:].strip()\n",
    "            a_part = \"\"\n",
    "        else:\n",
    "\n",
    "            q_part, a_part = text, \"\"\n",
    "\n",
    "    # Q : 제거\n",
    "    q_part = re.sub(r\"^제목\\s*:\\s*\", \"\", q_part, flags=re.MULTILINE)\n",
    "    q_part = re.sub(r\"^Q\\s*:\\s*\", \"\", q_part, flags=re.MULTILINE)\n",
    "\n",
    "    q_part = clean_text(q_part)\n",
    "    a_part = clean_text(a_part)\n",
    "    return q_part, a_part\n",
    "\n",
    "\n",
    "def load_wide_from_csv(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    group_keys = [\"source\", \"consulting_date\", \"consulting_category\", \"consulting_content\"]\n",
    "\n",
    "    wide = (\n",
    "        df.pivot_table(\n",
    "            index=group_keys,\n",
    "            columns=\"classification_category\",\n",
    "            values=\"classification\",\n",
    "            aggfunc=lambda x: \" / \".join(sorted(set(x)))\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    wide = wide.rename(columns={\n",
    "        \"consulting_content\": \"full_text\",\n",
    "        \"상담 주제\": \"topic\",\n",
    "        \"상담 사유\": \"reason\",\n",
    "        \"상담 결과\": \"outcome\",\n",
    "        \"상담 요건\": \"requirement\",\n",
    "        \"상담 내용\": \"summary\",\n",
    "    })\n",
    "    return wide\n",
    "\n",
    "\n",
    "def build_qa_dataset_from_wide(wide: pd.DataFrame) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    wide DataFrame에서 question / answer 추출.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _, row in wide.iterrows():\n",
    "        full_text = row.get(\"full_text\", \"\")\n",
    "        q, a = parse_question_answer(full_text)\n",
    "\n",
    "        if len(q) < 5 or len(a) < 5:\n",
    "            continue\n",
    "\n",
    "        data.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": a,\n",
    "            \"topic\": row.get(\"topic\", \"\"),\n",
    "            \"reason\": row.get(\"reason\", \"\"),\n",
    "            \"outcome\": row.get(\"outcome\", \"\"),\n",
    "            \"requirement\": row.get(\"requirement\", \"\"),\n",
    "            \"summary\": row.get(\"summary\", \"\"),\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "def split_dataset(all_data: List[Dict[str, str]], test_ratio: float = 0.1):\n",
    "    total = len(all_data)\n",
    "    test_size = max(1, int(total * test_ratio))\n",
    "    train_data = all_data[:-test_size]\n",
    "    test_data = all_data[-test_size:]\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2. LoRA Generator 학습용 Dataset & Trainer (SFT)\n",
    "# =====================================================================\n",
    "\n",
    "class GeneratorSFTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generator LoRA 학습용 SFT Dataset.\n",
    "    prompt = 시스템 지침 + Q\n",
    "    target = A\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_length=512, base_sys_prompt=\"\"):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.base_sys_prompt = base_sys_prompt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        q = item[\"question\"]\n",
    "        a = item[\"answer\"]\n",
    "\n",
    "        # 간단한 chat-style 프롬프트 템플릿\n",
    "        prompt = (\n",
    "            f\"<|system|>\\n{self.base_sys_prompt}\\n\\n\"\n",
    "            f\"<|user|>\\n{q}\\n\\n\"\n",
    "            f\"<|assistant|>\\n\"\n",
    "        )\n",
    "        # LM 학습은 prompt + answer 전체를 labels로 사용\n",
    "        full_text = prompt + a\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            full_text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = enc[\"input_ids\"][0]\n",
    "        attention_mask = enc[\"attention_mask\"][0]\n",
    "\n",
    "        # causal LM 이므로 labels = input_ids\n",
    "        labels = input_ids.clone()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "\n",
    "def train_lora_generator(\n",
    "    train_data,\n",
    "    output_dir=\"./gen_lora\",\n",
    "    base_model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    base_sys_prompt=\"당신은 한국 공공기관의 민원 답변을 작성하는 공무원 보조 AI입니다.\",\n",
    "    max_length=512,\n",
    "    batch_size=2,\n",
    "    num_epochs=1,\n",
    "    lr=5e-5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generator LoRA SFT 학습 스켈레톤.\n",
    "    실제로는 epoch, lr, batch_size 등을 상황에 맞게 조정.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    # LoRA 설정 \n",
    "    peft_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "\n",
    "    train_dataset = GeneratorSFTDataset(\n",
    "        train_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        base_sys_prompt=base_sys_prompt,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=lr,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"epoch\",\n",
    "        bf16=True,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # LoRA 어댑터만 저장\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"[Generator LoRA] Saved to {output_dir}\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3. LoRA Verifier 학습용 Dataset & Trainer (회귀)\n",
    "# =====================================================================\n",
    "\n",
    "class VerifierDataset(Dataset):\n",
    "    \"\"\"\n",
    "    (질문 + 답변) -> quality_score(0~1) 회귀용 Dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        texts = []\n",
    "        labels = []\n",
    "\n",
    "        for item in data:\n",
    "            q = item[\"question\"]\n",
    "            a = item[\"answer\"]\n",
    "\n",
    "            # 간단한 텍스트 결합\n",
    "            text = f\"[COMPLAINT]\\n{q}\\n\\n[ANSWER]\\n{a}\"\n",
    "            texts.append(text)\n",
    "\n",
    "            L = len(a)\n",
    "            score = max(0.3, min(1.0, L / 1500.0))\n",
    "            labels.append(score)\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = enc[\"input_ids\"][0]\n",
    "        attention_mask = enc[\"attention_mask\"][0]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": label,\n",
    "        }\n",
    "\n",
    "\n",
    "def train_lora_verifier(\n",
    "    train_data,\n",
    "    output_dir=\"./verifier_lora\",\n",
    "    base_model_name=\"distilbert-base-multilingual-cased\",\n",
    "    max_length=256,\n",
    "    batch_size=8,\n",
    "    num_epochs=1,\n",
    "    lr=2e-5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Verifier LoRA 회귀 학습 스켈레톤.\n",
    "    지금은 pseudo label 사용. 나중에 실제 품질 라벨로 교체.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        base_model_name,\n",
    "        num_labels=1,\n",
    "        problem_type=\"regression\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\",\n",
    "    )\n",
    "    model = get_peft_model(base_model, peft_config)\n",
    "\n",
    "    train_dataset = VerifierDataset(\n",
    "        train_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=lr,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"epoch\",\n",
    "        bf16=True,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        return {}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"[Verifier LoRA] Saved to {output_dir}\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 4. DBSCAN 기반 질문 클러스터러 \n",
    "# =====================================================================\n",
    "\n",
    "class ComplaintClusterer:\n",
    "    def __init__(self, model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"):\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "        self.dbscan = DBSCAN(eps=0.7, min_samples=5, metric=\"cosine\")\n",
    "        self.embeddings = None\n",
    "        self.labels = None\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.embeddings = self.embedder.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "        self.dbscan.fit(self.embeddings)\n",
    "        self.labels = self.dbscan.labels_\n",
    "        print(\"클러스터 개수(노이즈 포함):\", len(set(self.labels)))\n",
    "\n",
    "    def describe_cluster(self, k: int, texts: List[str], topn: int = 5) -> List[str]:\n",
    "        if self.labels is None:\n",
    "            return []\n",
    "        idxs = [i for i, lab in enumerate(self.labels) if lab == k]\n",
    "        return [texts[i][:200] for i in idxs[:topn]]\n",
    "\n",
    "    def similar_examples(self, text: str, texts: List[str], topn: int = 5) -> List[str]:\n",
    "        if self.embeddings is None:\n",
    "            return []\n",
    "        v = self.embedder.encode([text], convert_to_numpy=True)[0]\n",
    "        sims = self.embeddings @ v / (np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(v) + 1e-8)\n",
    "        idxs = np.argsort(-sims)[:topn]\n",
    "        return [texts[i][:200] for i in idxs]\n",
    "\n",
    "\n",
    "def refine_question_with_cluster_hints(\n",
    "    raw_question: str,\n",
    "    clusterer: ComplaintClusterer,\n",
    "    train_questions: List[str],\n",
    "    generator_model_id: str = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Cluster 힌트를 이용해서 질문을 정제하는 LLM 호출 (스켈레톤).\n",
    "    실제로는 TinyLlama나 다른 경량 모델로 '질문 개선'만 수행.\n",
    "    여기서는 placeholder: 그냥 raw_question 반환.\n",
    "    \"\"\"\n",
    "    \n",
    "    return raw_question.strip()\n",
    "\n",
    "\n",
    "# 5. Bandit + Generator + Verifier 엔진\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PromptArmConfig:\n",
    "    name: str\n",
    "    description: str\n",
    "    feature_vector: np.ndarray  # shape = (d,)\n",
    "\n",
    "\n",
    "class LogisticPromptBandit:\n",
    "    \"\"\"\n",
    "    프롬프트 전략 선택용 logistic bandit (UCB).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        lambda_reg: float = 1.0,\n",
    "        eta: float = 0.1,\n",
    "        beta: float = 1.0,\n",
    "    ):\n",
    "        self.arms = arms\n",
    "        self.n_arms = len(arms)\n",
    "        self.d = arms[0].feature_vector.shape[0]\n",
    "\n",
    "        self.w = np.zeros((self.n_arms, self.d))\n",
    "        self.H = [lambda_reg * np.eye(self.d) for _ in range(self.n_arms)]\n",
    "\n",
    "        self.eta = eta\n",
    "        self.beta = beta\n",
    "\n",
    "    def _sigmoid(self, z: float) -> float:\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def select_arm(self) -> int:\n",
    "        scores = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = arm.feature_vector\n",
    "            mean = float(self.w[a_idx].dot(x))\n",
    "            invH = np.linalg.inv(self.H[a_idx])\n",
    "            var = float(x.T @ invH @ x)\n",
    "            ucb = self.beta * np.sqrt(max(var, 1e-12))\n",
    "            scores.append(mean + ucb)\n",
    "        return int(np.argmax(scores))\n",
    "\n",
    "    def update(self, arm_idx: int, reward: float):\n",
    "        x = self.arms[arm_idx].feature_vector\n",
    "        z = float(self.w[arm_idx].dot(x))\n",
    "        p = self._sigmoid(z)\n",
    "        grad = -(reward - p) * x\n",
    "        self.H[arm_idx] += np.outer(x, x)\n",
    "        invH = np.linalg.inv(self.H[arm_idx])\n",
    "        step = self.eta * (invH @ grad)\n",
    "        self.w[arm_idx] -= step\n",
    "\n",
    "    def explain_current_strategy(self) -> List[str]:\n",
    "        lines = []\n",
    "        for a_idx, arm in enumerate(self.arms):\n",
    "            x = arm.feature_vector\n",
    "            z = float(self.w[a_idx].dot(x))\n",
    "            p = self._sigmoid(z)\n",
    "            lines.append(\n",
    "                f\"[{arm.name}] 예상 성공도 ≈ {p:.3f} | \"\n",
    "                f\"feature={np.round(x, 2)} | 설명: {arm.description}\"\n",
    "            )\n",
    "        return lines\n",
    "\n",
    "\n",
    "def build_default_arms() -> List[PromptArmConfig]:\n",
    "    return [\n",
    "        PromptArmConfig(\n",
    "            name=\"법률-정책 최우선\",\n",
    "            description=\"법령, 조례, 내부지침과의 일치성을 최우선으로 하고 책임 범위를 분명히 하는 보수적 답변.\",\n",
    "            feature_vector=np.array([0.9, 0.6, 0.4, 0.8, 0.7]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"민원인 공감형\",\n",
    "            description=\"민원인의 감정과 상황을 공감하며, 이해하기 쉬운 언어로 절차와 한계를 설명.\",\n",
    "            feature_vector=np.array([0.6, 0.7, 0.9, 0.3, 0.5]),\n",
    "        ),\n",
    "        PromptArmConfig(\n",
    "            name=\"해결책 제안형\",\n",
    "            description=\"현실적으로 가능한 대안과 행동 옵션을 최대한 제시하는 해결 중심 답변.\",\n",
    "            feature_vector=np.array([0.7, 0.9, 0.7, 0.4, 0.8]),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "BASE_SYS_PROMPT = (\n",
    "    \"당신은 한국 공공기관의 민원 처리 보조 AI입니다. \"\n",
    "    \"사실과 법령에 기반해 답변하고, 정책과 조례를 임의로 확대 해석하지 마세요. \"\n",
    "    \"항상 처리 가능 범위와 한계를 분명히 설명하고, \"\n",
    "    \"답변 마지막에는 '실제 처리 여부는 담당 부서의 최종 판단에 따릅니다.'라고 명시하세요.\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_prompt_from_arm(complaint_text: str, arm: PromptArmConfig) -> str:\n",
    "    return (\n",
    "        f\"아래 민원에 대해 답변을 작성하되, 다음 전략 프로필을 따르세요.\\n\\n\"\n",
    "        f\"[전략 이름]\\n{arm.name}\\n\\n\"\n",
    "        f\"[전략 설명]\\n{arm.description}\\n\\n\"\n",
    "        f\"[민원 내용]\\n{complaint_text}\\n\\n\"\n",
    "        f\"[추가 지침]\\n\"\n",
    "        f\"- 관련 법령/정책과의 일치성을 확인하고, 처리 가능/불가능을 명확히 구분하세요.\\n\"\n",
    "        f\"- 민원인이 이해하기 쉬운 구조로 답변하고, 필요한 경우 대안/절차를 제시하세요.\\n\"\n",
    "        f\"- 과도한 약속이나 확정적인 표현은 피하고, '담당 부서의 최종 판단'이 필요함을 밝혀주세요.\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "class LlamaGeneratorWrapper:\n",
    "    def __init__(self, base_model_name, lora_dir: Optional[str] = None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model_name,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        if lora_dir is not None and os.path.isdir(lora_dir):\n",
    "            model = PeftModel.from_pretrained(model, lora_dir)\n",
    "            print(f\"[Generator] LoRA loaded from {lora_dir}\")\n",
    "        else:\n",
    "            print(\"[Generator] LoRA not found. Using base model only.\")\n",
    "\n",
    "        self.pipe = transformers.pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "\n",
    "    def generate(self, system_prompt: str, user_prompt: str, max_new_tokens=512) -> str:\n",
    "        msgs = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "        out = self.pipe(\n",
    "            msgs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.3,\n",
    "            top_p=0.9,\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        if isinstance(out, list):\n",
    "            for m in out:\n",
    "                if isinstance(m, dict) and m.get(\"role\") == \"assistant\":\n",
    "                    return m.get(\"content\", \"\").strip()\n",
    "        return str(out)\n",
    "    \n",
    "class VerifierWrapper:\n",
    "    def __init__(self, base_model_name, lora_dir: Optional[str] = None, device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            base_model_name,\n",
    "            num_labels=1,\n",
    "            problem_type=\"regression\",\n",
    "            torch_dtype=torch.float32 if device == \"cpu\" else torch.bfloat16,\n",
    "        )\n",
    "        if lora_dir is not None and os.path.isdir(lora_dir):\n",
    "            model = PeftModel.from_pretrained(model, lora_dir)\n",
    "            print(f\"[Verifier] LoRA loaded from {lora_dir}\")\n",
    "        else:\n",
    "            print(\"[Verifier] LoRA not found. Using base model only.\")\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, complaint: str, answer: str) -> float:\n",
    "        text = f\"[COMPLAINT]\\n{complaint}\\n\\n[ANSWER]\\n{answer}\"\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**enc).logits\n",
    "        score = torch.sigmoid(logits)[0].item()\n",
    "        return float(max(0.0, min(1.0, score)))\n",
    "\n",
    "class MetaVerifier:\n",
    "    \"\"\"\n",
    "    - LM 기반 품질 점수: f_lm(Q, A)\n",
    "    - 클러스터 일관성 점수: f_cluster(Q, A, clusterer)\n",
    "    - 전략 일치도 점수: f_arm(A, arm)\n",
    "    을 합쳐서 최종 reward 반환.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lm_verifier: VerifierWrapper,\n",
    "                 clusterer: Optional[ComplaintClusterer] = None,\n",
    "                 train_questions: Optional[List[str]] = None):\n",
    "        self.lm_verifier = lm_verifier\n",
    "        self.clusterer = clusterer\n",
    "        self.train_questions = train_questions or []\n",
    "\n",
    "    def _cluster_consistency(self, question: str, answer: str) -> float:\n",
    "        \"\"\"\n",
    "        DBSCAN 기반으로 '이 답변이 이 질문 유형에 잘 맞는지'를\n",
    "        아주 거친 형태로 점수화하는 자리.\n",
    "        지금은 placeholder로 0.5~1.0 사이 정도로만 두고,\n",
    "        나중에 sentence-transformers로 Q/A 임베딩 비교해서 넣자.\n",
    "        \"\"\"\n",
    "        if self.clusterer is None or self.clusterer.embeddings is None:\n",
    "            return 0.7 \n",
    "\n",
    "        # Q 임베딩 → 가까운 클러스터/예시 Q들 → A도 embed해서 유사도 비교\n",
    "        return 0.7\n",
    "\n",
    "    def _arm_alignment(self, answer: str, arm: PromptArmConfig) -> float:\n",
    "        \"\"\"\n",
    "        arm 전략과 답변 내용이 얼추 맞는지 간단한 키워드 매칭으로 평가.     \n",
    "        \"\"\"\n",
    "        txt = answer[:2000]\n",
    "\n",
    "        if \"법률-정책 최우선\" in arm.name:\n",
    "            keywords = [\"법\", \"조항\", \"시행령\", \"조례\", \"규정\"]\n",
    "        elif \"공감형\" in arm.name:\n",
    "            keywords = [\"이해\", \"불편을 드려\", \"죄송\", \"공감\", \"도움이 되셨으면\"]\n",
    "        elif \"해결책 제안형\" in arm.name:\n",
    "            keywords = [\"대안\", \"조치\", \"절차\", \"신청\", \"문의\", \"방법\"]\n",
    "        else:\n",
    "            keywords = []\n",
    "\n",
    "        if not keywords:\n",
    "            return 0.5\n",
    "\n",
    "        hit = sum(1 for kw in keywords if kw in txt)\n",
    "        return max(0.3, min(1.0, hit / max(1, len(keywords))))\n",
    "\n",
    "    def evaluate(self, question: str, answer: str, arm: PromptArmConfig) -> float:\n",
    "        # 1) LM 기반 품질\n",
    "        s_lm = self.lm_verifier.evaluate(question, answer)\n",
    "\n",
    "        # 2) 클러스터 일관성\n",
    "        s_cluster = self._cluster_consistency(question, answer)\n",
    "\n",
    "        # 3) 전략 일치도\n",
    "        s_arm = self._arm_alignment(answer, arm)\n",
    "\n",
    "        # 4) 가중합으로 최종 reward\n",
    "        reward = (\n",
    "            0.5 * s_lm +\n",
    "            0.3 * s_cluster +\n",
    "            0.2 * s_arm\n",
    "        )\n",
    "        return float(max(0.0, min(1.0, reward)))\n",
    "\n",
    "\n",
    "class PromptBanditEngine:\n",
    "    def __init__(\n",
    "        self,\n",
    "        arms: List[PromptArmConfig],\n",
    "        generator: LlamaGeneratorWrapper,\n",
    "        lm_verifier: VerifierWrapper,\n",
    "        clusterer: Optional[ComplaintClusterer] = None,\n",
    "        train_questions: Optional[List[str]] = None,\n",
    "    ):\n",
    "        self.bandit = LogisticPromptBandit(arms=arms)\n",
    "        self.generator = generator\n",
    "        self.meta_verifier = MetaVerifier(\n",
    "            lm_verifier=lm_verifier,\n",
    "            clusterer=clusterer,\n",
    "            train_questions=train_questions,\n",
    "        )\n",
    "\n",
    "    def step(self, raw_complaint: str) -> Dict[str, Any]:\n",
    "        arm_idx = self.bandit.select_arm()\n",
    "        arm = self.bandit.arms[arm_idx]\n",
    "\n",
    "        refined_q = refine_question_with_cluster_hints(raw_complaint, self.meta_verifier.clusterer, ...)\n",
    "\n",
    "        user_prompt = build_prompt_from_arm(refined_q, arm)\n",
    "        answer = self.generator.generate(BASE_SYS_PROMPT, user_prompt)\n",
    "\n",
    "        reward = self.meta_verifier.evaluate(refined_q, answer, arm)\n",
    "\n",
    "        self.bandit.update(arm_idx, reward)\n",
    "\n",
    "        return {\n",
    "            \"arm_idx\": arm_idx,\n",
    "            \"arm_name\": arm.name,\n",
    "            \"answer\": answer,\n",
    "            \"reward\": reward,\n",
    "            \"strategy_view\": self.bandit.explain_current_strategy(),\n",
    "        }\n",
    "\n",
    "\n",
    "# 6. 배치 평가 + 인터랙티브 질의\n",
    "\n",
    "\n",
    "def evaluate_batch(engine: PromptBanditEngine, test_data, out_csv=\"batch_results_sample.csv\"):\n",
    "    logs = []\n",
    "    for item in tqdm(test_data):\n",
    "        q = item[\"question\"]\n",
    "        out = engine.step(q)\n",
    "        logs.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": out[\"answer\"],\n",
    "            \"reward\": out[\"reward\"],\n",
    "            \"arm\": out[\"arm_name\"],\n",
    "        })\n",
    "    df = pd.DataFrame(logs)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def interactive_loop(engine: PromptBanditEngine):\n",
    "    \"\"\"\n",
    "    실시간 질의 응답 루프\n",
    "    \"\"\"\n",
    "    print(\"=== 민원 질문 입력 (종료: 빈 줄 + 엔터) ===\")\n",
    "    while True:\n",
    "        q = input(\"\\n[민원] > \").strip()\n",
    "        if not q:\n",
    "            print(\"종료합니다.\")\n",
    "            break\n",
    "        out = engine.step(q)\n",
    "        print(f\"\\n[선택된 전략] {out['arm_name']}\")\n",
    "        print(\"\\n[답변]\\n\", out[\"answer\"][:1000])\n",
    "        print(f\"\\n[Verifier score / reward] {out['reward']:.3f}\")\n",
    "        print(\"\\n[전략 상태]\")\n",
    "        for line in out[\"strategy_view\"]:\n",
    "            print(\" \", line)\n",
    "\n",
    "# main 함수\n",
    "\n",
    "def main(\n",
    "    csv_path: str = \"중앙행정기관.csv\",\n",
    "    train_gen_lora: bool = True,      # True로 두면 Generator LoRA 학습 수행\n",
    "    train_ver_lora: bool = False,      # True로 두면 Verifier LoRA 학습 수행\n",
    "    eval_samples: int = 100,            # test set에서 평가할 샘플 개수\n",
    "):\n",
    "    # 1) 데이터 로드 + Q/A 구축\n",
    "    print(f\"[MAIN] CSV 로드: {csv_path}\")\n",
    "    wide = load_wide_from_csv(csv_path)\n",
    "    qa_data = build_qa_dataset_from_wide(wide)\n",
    "    print(f\"[MAIN] 총 Q/A 쌍 개수: {len(qa_data)}\")\n",
    "\n",
    "    if len(qa_data) < 20:\n",
    "        print(\"[MAIN] 데이터가 너무 적습니다. CSV/파싱을 확인하세요.\")\n",
    "        return\n",
    "\n",
    "    train_data, test_data = split_dataset(qa_data, test_ratio=0.1)\n",
    "    print(f\"[MAIN] Train: {len(train_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "    # 2) LoRA 학습\n",
    "    if train_gen_lora:\n",
    "        print(\"\\n[MAIN] >>> Generator LoRA 학습 시작\")\n",
    "        train_lora_generator(\n",
    "            train_data,\n",
    "            output_dir=\"./gen_lora\",\n",
    "            base_model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "        )\n",
    "        print(\"[MAIN] >>> Generator LoRA 학습 완료\")\n",
    "\n",
    "    if train_ver_lora:\n",
    "        print(\"\\n[MAIN] >>> Verifier LoRA 학습 시작\")\n",
    "        train_lora_verifier(\n",
    "            train_data,\n",
    "            output_dir=\"./verifier_lora\",\n",
    "            base_model_name=\"distilbert-base-multilingual-cased\",\n",
    "        )\n",
    "        print(\"[MAIN] >>> Verifier LoRA 학습 완료\")\n",
    "\n",
    "    # 3) DBSCAN 기반 질문 클러스터링\n",
    "    train_questions = [d[\"question\"] for d in train_data]\n",
    "    clusterer = ComplaintClusterer()\n",
    "    clusterer.fit(train_questions)\n",
    "\n",
    "    # 4) Generator / Verifier / Bandit 엔진 초기화\n",
    "    print(\"\\n[MAIN] Generator / Verifier / Bandit 엔진 초기화\")\n",
    "\n",
    "    generator = LlamaGeneratorWrapper(\n",
    "        base_model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "        lora_dir=\"./gen_lora\",   \n",
    "    )\n",
    "    verifier = VerifierWrapper(\n",
    "        base_model_name=\"distilbert-base-multilingual-cased\",\n",
    "        lora_dir=\"./verifier_lora\", \n",
    "        device=\"cpu\",             \n",
    "    )\n",
    "\n",
    "    arms = build_default_arms()\n",
    "    engine = PromptBanditEngine(arms=arms, generator=generator, verifier=verifier)\n",
    "\n",
    "    # 5) Test 일부 평가\n",
    "    n_eval = min(eval_samples, len(test_data))\n",
    "    print(f\"\\n[MAIN] >>> Test set 일부({n_eval}개)에 대한 평가 실행\")\n",
    "    df_res = evaluate_batch(engine, test_data[:n_eval], out_csv=\"batch_results_sample.csv\")\n",
    "    print(df_res.head())\n",
    "\n",
    "    # 6) 실시간 질의 루프 (서비스 시뮬레이션)\n",
    "    # interactive_loop(engine)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main(csv_path=\"중앙행정기관.csv\", train_gen_lora=False, train_ver_lora=False, eval_samples=10)\n",
    "    main(csv_path=\"중앙행정기관.csv\", train_gen_lora=True, train_ver_lora=False, eval_samples=10)\n",
    "\n",
    "    # main()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
